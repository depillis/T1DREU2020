\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1.0in]{geometry}
\usepackage[bottom]{footmisc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{tcolorbox}
\usepackage{subcaption}
\usepackage{float}
\usepackage{multirow}
\usepackage[toc,page]{appendix}
\usepackage{adjustbox}



\title{MCMC}
\author{Subteam 1}
\date{June 2020}

\begin{document}
\maketitle

\section{Bayesian Techniques} \label{Bayesian_Techniques}
Bayesian inference is a powerful tool in parameter estimation for biological systems that begins with previously known information and updates a system using new, incoming data \cite{bayesian_param_inf}.  In particular, Bayesian inference techniques have been used to parameterize a variety of biological models and systems, \cite{bayesian_param_inf_ex1}, \cite{bayesian_param_inf_ex2}. In the following sections, we outline the basic mathematical concepts behind the Bayesian inference technique Markov Chain Monte Carlo (MCMC) method, introduce two specific implementations of MCMC methods, and parameterize two different biological nonlinear ODE systems.
\subsection{Bayesian Parameter Estimation}
Bayesian parameter estimation is a process of inferring a posterior probability density function (PDF) over a model's possible parameters given data, $D$, for some model, $M$ \cite{astrostats}. This PDF can be evaluated for a set of parameters, giving its probability. Parameters of a system are treated as random variables and realized as $\theta = [p_1, p_2,...,p_n]$, where $p_i$ is a parameter of a modeling system. They follow distributions that incorporate both \emph{a priori} knowledge (mathematical models, theory etc.) about their values, as well as information obtained from data collection. In the inverse problem of estimating a system's parameters, $\theta$, a variety of Bayesian techniques can serve to find a posterior density, the post-parameterization distribution of parameter values based on sampled data and a given model \cite{bayesprior}. This technique relies on Bayes' Theorem which is defined as follows:
\begin{equation} \label{eq:1mcmc}
P(\theta | D, M) = \frac{P(D|\theta, M)P(\theta|M)}{P(D|M)}
\end{equation}
where $\theta$ denotes a set of parameters. $P(D|\theta, M)$ is referred to as the \emph{likelihood} and denotes the probability of the data given the current parameters and model \cite{astrostats}. $P(\theta|M)$, or the \emph{prior}, gives the probability of a set of parameters for a given model, before the data can inform the system \cite{astrostats}. Finally, the denominator $P(D|M)$ is known as the \emph{evidence} \cite{astrostats}. The evidence (also called the normalization constant of the posterior probability) does not depend on $\theta$. In mathematical terms, because our posterior, $P(\theta|D,M)$ is a \textit{density function}, we need the right hand side of \textbf{Eq. \ref{eq:1mcmc}} to integrate to 1 (and avoid a situation of dividing by 0) \cite{bayesprior}, without the normalization constant, this is not possible. However, it is often difficult to calculate $P(D|M)$ (in closed-form) and many mathematicians choose to work with a variation of Bayes' Theorem:
\begin{equation} \label{eq:2mcmc}
P(\theta|D,M) \propto P(D|\theta,M)P(\theta|M)
\end{equation}
as it is possible to compute the priors and likelihoods. We work initially with \textbf{Eq. \ref{eq:1mcmc}} in this tutorial, but in the process we simplify and return to \textbf{Eq. \ref{eq:2mcmc}} (as is detailed later). Thus the quality of posterior estimation relies heavily on choices of the likelihood and prior which are informed by \textit{a priori} knowledge.
\subsubsection{The Curse of Dimensionality}
Many models have a significant number of parameters which leads to a high-dimensional parameter space, and thus a high dimensional posterior PDF. The best-fit set of of parameters for the model would be located at the peak of this multi-dimensional PDF, as these are, by definition the parameters located at the highest probability of the overall modeling system. 
\par Due to the unknown shape of the PDF, this maximum likelihood cannot be found analytically. Additionally, searching for it directly (discrete calculations for example) poses a challenge. While sufficiently sampling a one-dimensional PDF might require $N$ samples, sufficiently sampling a two-dimensional PDF requires building a grid of $N^{2}$ samples, and a $j$-dimensional PDF consequently requires a hypercube of $N^{j}$ samples. This exponential increase is known as the \emph{curse of dimensionality} \cite{astrostats}. Evaluating the posterior PDF for $N^{j}$ samples is computationally infeasible. Moreover, the probability of the majority of the these coordinates is very small adding to the computational difficulty. To overcome the curse of dimensionality, we instead look to \emph{sample} the posterior PDF directly. In effect, these samples simulate the distribution itself and feasible predicted values of parameters can be extracted from the simulation. One class of methods for such sampling is known as Markov Chain Monte Carlo methods, or MCMC methods. We explore two algorithms within MCMC to parameterize our simple example system. 

\section{Markov Chain Monte Carlo Sampling} \label{Markov_Chain_Monte_Carlo_Sampling}
Markov Chain Monte Carlo methods are used to describe posterior distributions when there is incomplete knowledge of the distribution's properties (such as its mean or variance) \cite{MLEvsBayes_powerpoint}. 
\par The idea driving MCMC is that of \textbf{Monte Carlo} methods. We are working in probabilities (via Bayes' Theorem), thus we rely on the probabilistic Monte Carlo method in which we observe quantities chosen to simulate the physical or biological processes of our system and infer a solution from their behavior \cite{montecarlo}. In our model specifically, we draw samples of parameters from an arbitrary probability density using random numbers drawn from a simpler distribution (astrostats cite) and infer posterior probabilities. MCMC uses a \textbf{Markov Chain} to perform \emph{rejection sampling} - that is, given a proposal distribution (a distribution of parameter values that we draw candidates from), we draw samples and penalize with an acceptance criteria (a ratio). Briefly, a Markov chain is a process in which we move among a set of elements $X$ according to a specified probability. Beginning at element $x_1 \in X$ we move to $x_2 \in X$ according to a probability distribution $P(x_1, *)$ which depends only on $x_1$ \cite{markovchains}. We use an asterisk to signify a multitude of possible probabilistic rules that could be applied that depend on the specifics of a model. The Markov ``chain"" refers to the order and values of elements in $X$ that we have visited (or collected).
The MCMC aspect of this algorithm establishes a random walk over the parameter space such that we can preferentially sample regions of high probability. Furthermore, since each `step' along this walk is only dependent on the previous, we classify the MCMC as a first-order Markovian process \cite{firstorderMarkovian}. 

\par The umbrella of MCMC methods is broad, but here we introduce implementations of the simplest algorithm, Metropolis MCMC, as well as a method derived from Metropolis, delayed rejection adaptive Metropolis (DRAM) MCMC. We find that looking at these two methods of sampling gives the reader a good idea of the range of capabilities that MCMC can provide for parameterization. Metropolis MCMC provides the most basic search in parameter space by finding local maxima. DRAM on the hand, increases the likelihood of finding global maxima or minima and allows the algorithm to search lower probability parameter space.

\subsection{Defining Bayes' Theorem} 
Bayes' Theorem is the underlying framework in the MCMC algorithm of accepting and rejecting samples. In this section we further specify elements of Bayes' Theorem in terms of a mathematical model and its parameters following a tutorial in \cite{astrostats}. We introduce two new concepts: the proposal distribution from which we draw parameter samples and the acceptance criteria which we use to accept and reject candidates.
\subsubsection{The Prior Distribution} The \emph{prior function} is the uncertainty that we have about a specific set of parameters \emph{before} we observe any data and informs us how likely we are to have sampled that set of parameters \cite{astrostats}. We can specify the prior distribution based on \textit{a priori} knowledge about our biological system \cite{bayesprior}. For example, if we know from previous experimentation the range of variation that we expect a parameter to exhibit, we can constrain the parameter candidates that we draw accordingly. However, when we know nothing about our parameter values, we initialize an uninformative prior distribution - a uniform distribution:
\begin{center} \label{eq:3mcmc}
\begin{align}
  P(\theta|M) = \left\{ \begin{array}{cc} 
                \frac{1}{b-a} & \hspace{5mm} a \leq \theta \leq b \\
                0 & \hspace{5mm} otherwise \\
                \end{array} \right.
\end{align}
\end{center}
It is important to note that we must know enough about the parameters of the system in order to make a decision about the bounds of the uniform distribution. For example, in a biological system we could say that it is biologically infeasible for a particular parameter value to be negative. In effect, we do not want our prior function to be 0 because in computing the acceptance ratio (discussed in 2.1.5), we will encounter a situation of dividing by 0. Consequently, the prior distribution becomes
\begin{equation} \label{eq:4mcmc}
P(\theta|M) = \frac{1}{b-a}
\end{equation}
That is for any values of $\theta$ our prior distribution will be never be 0. It is important to point out with this definition, we have specified the same uniform interval, $[a, b]$, for all parameter sets. Now what does this mean in the context of parameterization and why would we choose to do this? If we truly have no \emph{a priori} information about our model and its parameters, then we do not want to implement any bias when accepting and rejecting samples. In other words, we want each sample to be equally likely (in terms of being informed by the prior) and the uniform prior achieves this for us. 
\subsubsection{The Likelihood Function} \label{The_Likelihood_Function} The \emph{likelihood function} represents the relationships between independent evaluations of a model (given specified parameters) and it informs us \emph{how} to accept samples of parameters from the specified proposal distribution. In a biological model, we would assume that there exists some amount of error, or noise, within the model itself. If we have $D = \{x_n, y_n\}$ with $n$ data points, then our model $M$ predicts values of $y$ to be
\begin{equation} \label{eq:5mcmc}
y = f(x) + \epsilon
\end{equation}
where $f(x)$ is the evaluation of the ODE system and $\epsilon$ is our system noise. The most general assumption we can make is that the noise is an independent and identically distributed (every random variable has the same distribution and each is independent of the others) Gaussian distribution with a mean of 0 and a standard deviation $\sigma$. 
\par The distribution of the likelihood informs us how different evaluations of the model are distributed given varying parameter values. Thus, when we accept sampled parameter values, we will do so according to the likelihood function's distribution. Often, the likelihood is given as a normal distribution
\begin{equation} \label{eq:6mcmc}
    P(D|\theta, M) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{SS_{\theta}}{{2\sigma^2}}}
\end{equation}
where $SS_{\theta} = \sum_{i=1}^{n}[y_i - f_i(\theta)]^2$ is the sum of squares error between the predicted model and the original data and $\sigma$ refers to the standard deviation of the noise \cite{astrostats}.
\par It is important to note that $\sigma$ is often unknown. We may know that our system produces some noise, but we are not able to quantify it via a specific standard deviation. In this case, we can simply use an estimate for $\sigma$, denoted as $s$. There are a variety of ways to estimate $s$, however in practice, we use the following estimation
\begin{equation} \label{eq:7mcmc}
s^2 = \frac{SS_{\theta}}{n-p}
\end{equation}
where $n$ is the total number of data points, $p$ is the number of parameters and $SS_{\theta}$ is as defined above \cite{smithCh8}.
\subsubsection{The Posterior Distribution} The \emph{posterior distribution} is the accumulation of samples in the chain that are accepted and to which a distribution can be fitted. Not only can we extract the PDF of a set of parameters, we can extract individual parameter PDFs.
\subsubsection{The Proposal Distribution} We now must introduce a new element that is not a part of Bayes' Theorem: the proposal distribution. This is the distribution from which we draw the values of our samples. If we have \textit{a priori} knowledge about our parameter space, we can specify our own distribution, but when no knowledge is available, a normal distribution is often assumed \cite{astrostats} \cite{bayesprior}. For certain MCMC algorithms, like the Metropolis MCMC, the proposal distribution must be symmetrical \cite{smithCh8}. A proposal distribution $J$ is considered symmetrical if $J(\theta^{*}|\theta^{k-1}) = J(\theta^{k-1}|\theta^{*})$, where $\theta^*$ is the proposed sample and $\theta^{k-1}$ is the current sample \cite{smithCh8}. In symmetric sampling, the order of selecting parameters does not matter; that is, the probability of moving from sample $a$ to sample $b$ is the same as moving from $b$ to $a$.
\par In order to get the best parameterization of our model, we want to establish a proposal distribution from which we believe we will be able to sample the best values for our model. In practice, it is common to initialize a multivariate Gaussian distribution \cite{astrostats} \cite{mcmcstatlib}. We can implement a covariance matrix to represent this proposal distribution. The coefficients of this matrix will represent the effect that perturbations of varying parameter values may have on the system \cite{sensitivity_matrices1}. In our Gaussian proposal scenario, we define the proposal 
\begin{equation} \label{eq:8mcmc}
V = J(\theta^*|\theta{k-1})
\end{equation}
where $J$ is defined as a Jacobian output matrix \cite{sensitivity_matrices1} \cite{smithCh8}. The proposal is distributed as $N(\theta^{k-1}, V_{cov})$ where $V_{cov}$ is the covariance matrix for $\theta$ \cite{smithCh8}. (Note that $V_{cov}$ must be positive definite.) In the \texttt{mcmcstat} library function \texttt{mcmcrun}, this covariance matrix is computed internally \cite{mcmcstatlib}.
\par One way to construct $V$ by hand is to use a sensitivity matrix. Briefly, this matrix is calculated by computing the Jacobian matrix of the derivatives of the parameters and the model. For a more in-depth calculation of $V$ we refer the reader to \cite{smithCh8} and \cite{sensitivity_matrices1}.
\subsubsection{The Acceptance Criteria} As we pointed out before, the acceptance criteria is the element of MCMC sampling that allows the algorithm to accept and reject proposed samples in the Markov chain. We want to discriminate between samples of parameters based on their probabilities, only accepting the best (the most likely according to our likelihood, prior, and proposal functions) sets. To do this, we accept parameter sets according to a ratio, $\alpha$, which is a direct application of Bayes' Theorem \cite{astrostats}. While $\alpha$ may differ slightly according to the specific MCMC algorithm begin implemented, a basic ratio compares the posteriors of a proposed set of parameters ($\theta^*$) with the last accepted set of parameters ($\theta^{k-1}$) as follows:
\begin{equation} \label{eq:9mcmc}
\alpha = min(1, \frac{P(\theta^*|D, M)}{P(\theta^{k-1}|D,M)}) = min(1, \frac{\frac{P(D|\theta^*, M)P(\theta^*|M)}{P(D|M)}}{\frac{P(D|\theta^{k-1}, M)P(\theta^{k-1}|M)}{P(D|M)}}) = min(1, \frac{P(D|\theta^*, M)P(\theta^*|M)}{P(D|\theta^{k-1}, M)P(\theta^{k-1}|M)})
\end{equation}
Notice that the \emph{evidence} term of Bayes' Theorem (the denominator) cancels out. Intuitively, this cancellation makes sense because we are only interested in comparing the impact of different parameter sets on the model, but the evidence does not depend on the parameters at all. If 
\begin{equation} \label{eq:10mcmc}
P(D|\theta^*, M)P(\theta^*|M) \geq P(D|\theta^{k-1}, M)P(\theta^{k-1}|M)
\end{equation}
we accept $\theta^*$ with a probability of 1. If this is not the case, we still want to accept $\theta^*$ with some probability, the ratio between products of likelihoods and priors \cite{astrostats}. In initializing our MCMC algorithm, we assume that we will find a majority of our ``best" parameter values given the prior and likelihood functions that we chose. Thus, while a candidate may not be the best parameter set according to $\alpha$, it can still inform our posterior distribution. So, we want some probability of accepting any sampled parameter set. In addition, if we outright reject any candidate that does not meet the acceptance criterion, we run the risk of getting stuck in a very small range of values to sample from since our next parameter candidate depends directly on the previously sampled (and accepted) parameter set due to the Markovian process of the algorithm.
\par To get a better understanding of how $\alpha$ is constructed, let's use our Gaussian likelihood and uniform prior on the interval $[a, b]$. The acceptance criterion becomes
\begin{equation} \label{eq:11mcmc}
\alpha = min(1, \frac{P(D|\theta^*, M)(\frac{1}{b-a})}{P(D|\theta^{k-1},M)(\frac{1}{b-a})}) = min(1, \frac{\frac{1}{\sigma \sqrt{2\pi}} \exp^{\frac{SS_{\theta^*}}{{2\sigma^2}}}}{\frac{1}{\sigma \sqrt{2\pi}} \exp^{\frac{SS_{\theta^{k-1}}}{{2\sigma^2}}}})
\end{equation}
which simplifies to
\begin{equation} \label{eq:12mcmc}
    \alpha = min(1, exp^{-[-SS_{\theta^*} - SS_{\theta^{k-1}}]/2\sigma^2}) \cite{mcmcstatlib}
\end{equation}
\subsubsection{Overview} So how does sampling create a usable posterior distribution? Figure 1 illustrates the MCMC process.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/mcmc_procedure.png}
    \caption{Markov chain Monte Carlo sampling using random walk \cite{mcmcFig}}
\end{figure}
We start with a general pool of potential parameter values - our proposal distribution. As we iterate through the chain, accepting and rejecting a samples - using the acceptance criterion, eventually we can fit our accepted samples to a distribution, the posterior distribution.
\section{Metropolis MCMC} \label{Metropolis_MCMC}
The single-chain Metropolis MCMC algorithm is one of the most basic and widely implemented MCMC methods. The Metropolis algorithm is a special case of another common MCMC algorithm, the Metropolis-Hastings algorithm \cite{metropolis1953}. The Metropolis algorithm requires a symmetric proposal distribution, whereas Metropolis-Hastings does not \cite{smithCh8}. Below, we outline the algorithm for the the Metropolis MCMC method.\\
\begin{tcolorbox} \label{alg:met}
\textbf{\underline{Metropolis MCMC Algorithm (with an uninformative prior)}} 
\begin{enumerate}
    \item Set number of samples to take, $N$, and determine a burn-in period, $k_b$
    \item \label{step:2met} Determine an initial parameter guess, $\theta^0 = argmin_\theta \sum_{i=1}^{n}[M_i - f_i(\theta)]^2]$

    \item Set $SS_{\theta^0} = \sum_{i = 1}^{n}[y_i - f_i(\theta^0)]^2$ (for initial likelihood, see \ref{The_Likelihood_Function})
    \item Compute an initial error variance estimate $s_0^2 = \frac{SS_{\theta^0}}{n-p}$ ($n = $ number of data points, $p = $ number of parameters)
    \item Construct proposal covariance matrix $V$
    \item \label{step:6met}For each iteration of the chain, $k = 1,...,N$ 
    \begin{enumerate}
        \item Sample $z \sim N(0,I_p)$ 
        \item Construct candidate $\theta^* = \theta^{k-1}+ Vz$
        \item Compute $SS_{\theta^*} = \sum_{i = 1}^{n}[y_i - f_i(\theta^*)]^2$ (for likelihood)
        \item Compute acceptance criterion
            \begin{center}
                $\alpha(\theta^* | \theta^{k-1}) = min(1, \frac{P(\theta^* |D, M)}{P(\theta^{k-1}|D, M})) = min(1, e^{-[SS_{\theta^*}-SS_{\theta^{k-1}}/2s_{k-1}^2]})$
            \end{center}
        \item Accept $\theta^*$ with probability 1 if $\alpha \geq 1$ and accept it with probability $\alpha$ if $\alpha < 1$.
        \begin{itemize}
            \item If $\theta^*$ is accepted
            \begin{center}
                $\theta^k = \theta^*$, $SS_{\theta^k} = SS_{\theta^*}$
            \end{center}
            \item Else
            \begin{center}
                $\theta^k = \theta^{k-1}$, $SS_{\theta^k} = SS_{\theta^{k-1}}$
            \end{center}
        \end{itemize}
        \item If $k > k_b$ collect $\theta^*$ in posterior matrix $P$, else discard.
        \item Update $s_k^2 = \frac{SS_{\theta^k}}{n-p}$
    \end{enumerate}
\end{enumerate}
\emph{Based on Smith (2014) Algorithm 8.5}
\end{tcolorbox}
\par We want to determine a number of samples to take, $N$ so that we can be sure that the resulting accepted parameter values approach the posterior distribution. Since we are sampling a parameter space via random-walk (since $\theta^*$ only relies on $\theta^{k-1}$), we want our algorithm to settle into an area of values that are highly likely to fit our model $M$. Thus, we want the chain to reach \emph{convergence} or a steady state. We can increase the likelihood of convergence occurring by performing \emph{burn-in} iterations of the chain. That is, we sample according to the Metropolis algorithm, however we must discard the beginning of the chain. This allows the chain to explore the parameter space, determine local maxima, and increases the probability that when we collect samples, they will reflect our desired posterior. The burn-in period is a sliding scale but it is typically  $\sim 10\%$ of the total chain length. (cite info about burn-in and convergence)
\par Note that in \textbf{Step \ref{step:2met}}, $\theta^0$ is found by evaluating the ODE model for the smallest parameter values. In practice we use the MATLAB \texttt{fmincon} function to do this. In \textbf{Step \ref{step:6met}a}, we sample a normal value $z$ such that $z \sim N(0,I_p)$ where $I_p$ is an identity matrix of $p$ by $p$ (the number of parameters) dimensions. Intuitively, $z$ is the random component of selecting a parameter set, and since our $V \sim N$, it $z$ must also be Gaussian. Note that in \textbf{Step \ref{step:6met}b}, we can see the Markovian influence as the candidate parameter is selected based on the previously accepted parameter set.

\subsection{Parameterizing Lotka-Volterra} Parameterizing a simple biological model using the Metropolis method is a good way to get familiar with the role of the elements of Bayes' Theorem and MCMC. Here we have parameterized the classic predator-prey model in MATLAB based on a tutorial in R originally intended for parameterizing a small non-linear ODE system \cite{mcmcstatlib}. It is important to note that MATLAB has its own implementation of the Metropolis MCMC method, \texttt{mhsample}. However, using this function requires an initialization routine similar to the one that we outline here. We are using the functions from the MATLAB \texttt{mcmcstat} library \cite{mcmcstatlib} and so we implement the components of the Metropolis MCMC method according to requirements of this algorithm. 
\par We consider 4 parameters in this model: $\theta = \{ \alpha, \: \beta,\: \delta,\: \gamma \}$. Given some initial prediction from our advisors, we initialize starting values and ranges for our parameters. As a general guide for creating our parameter ranges, we knew that our parameter values would never be negative. A good starting place would be to have a range of +/- a reasonable percentage (at maximum 100$\%$) and to constrain the lower end of the range to 0. We assume a Gaussian likelihood function in log (base e) form. Due to the sum of squares calculation for the likelihood function (see \textbf{\ref{The_Likelihood_Function}} we will be dealing with larger numbers (on the scale of 10e03 to 10e04). Thus, the natural log form is chosen for computational ease as we are able to compute sums rather than products and preventing exponential increase in values. The sum of squares between the model given parameter values and the original data is thus
\begin{equation} \label{eq:13mcmc}
lnP(D|\theta, M) = \sum_{k=1}^{N}lnP(y_k|x_k,\theta,M) = \sum_{k=1}^N SS_\theta^k
\end{equation}
 We also adopt a log-uniform prior
\begin{equation} \label{eq:14mcmc}
lnP(\theta|M) = ln\frac{1}{1-0} = 0
\end{equation}
The proposal distribution is determined for us in the MATLAB function \texttt{mcmcrun} using a covariance matrix. The acceptance criteria according to the \texttt{mcmcstat} library is defined as
\begin{equation} \label{eq:15mcmc}
\alpha = min(1, e^{ \lbrack {-0.5(\frac{\sum (SS_{\theta^*}-SS_{\theta^{k-1}})}{\sigma^2} + prior^*-prior^{k-1})} \rbrack})
\end{equation}
and thus with our assumptions simplifies to 
\begin{equation} \label{eq:16mcmc}
\alpha = min(1, e^{[ {-0.5(\frac{\sum (SS_{\theta^*}-SS_{\theta^{k-1}})}{\sigma^2}]}})
\end{equation}

With all of these assumptions and initializations, we can run the Metropolis MCMC algorithm and produce PDFs for each of our parameters. 
\subsubsection{Analyzing the Chain} \label{Analyzing_the_chain_Met}
Let's look at how our algorithm works by first visualizing the chain samples.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_mh_burninchain.png}
    \caption{Trace plot for the burn-in chain (10,000 samples) for the Metropolis MCMC parameterization of the Lotka-Volterra model. Each line shows the sampled parameter values. This figure illustrates the movement of the Markov chain as it samples parameters with the goal of finding the most likely range of values. As expected, the chain has not completely converged yet.}
    \label{fig:1mcmc}
\end{figure}
In \textbf{Figure \ref{fig:1mcmc}}, we can see the ``movement" of the chain as it looks around the parameter space drawing parameters values. We have implemented and visualized a burn-in period of 10,000 chain samples. In \textbf{Figure \ref{fig:1mcmc}}, it appears that the values of $\alpha$ and $\gamma$ are changing fairly drastically for every sample as evidenced by their more pronounced upward and downward trends. On the other hand, $\beta$ and $\delta$ seem to have less drastic value changes appearing to reach a steady state before 2,000 samples.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_mh_chain.png}
    \caption{Trace plot for the sampling chain (500,000 samples) for the DRAM MCMC parameterization of the Lotka-Volterra model. Each line shows the sampled parameter values. This figure visualizes each parameter value that has been sampled and accepted that will be used to build parameter PDFs. This chain visualization shows us that the algorithm is having a some difficult determining the most suitable mean as we see a distinct ``wave" pattern which indicates that chain mixing could be improved.}
    \label{fig:2mcmc}
\end{figure}
 In \textbf{Figure \ref{fig:2mcmc}}, we illustrate the final 500,000 values that our algorithm sampled. From a visual perspective, we can see that the chains appear to have achieved a steady-state; although the values still ``jump" up and down, they appear to do so around a certain value. For instance, $\alpha$ appears to move around 0.8 while $\gamma$ settles around 0.4. Often such a visual analysis of the chain as in \textbf{Figure \ref{eq:2mcmc}} is used to evaluate a chain's \textit{mixing time}. Briefly, mixing time refers to number of samples a chain requires to achieve a steady state and is directly related to the performance of the algorithm \cite{mixingtime}. Thus, a well-mixed chain is such a chain that in the given number of samples has achieved a steady state while a poorly mixed chain has not. \textbf{Figure \ref{fig:2mcmc}} demonstrates that the chain is fairly well mixed however as we will see later, it could be improved.
 \par The chain's ability to reach a steady state is important in determining the reliability of the final parameter distributions. We want our chain to reach a steady state or \emph{converge} by the time we complete sampling as this indicates the algorithm could not find ``better" or more likely values for the parameters within the constraints of the model. A \textit{burn-in} period gives the algorithm time to explore the parameter space and converge before sampling and collection for the distribution begins.
\par There are several formal techniques for confirming chain convergence, for example Geweke's diagnostic \cite{geweke1} and the Gelman-Rubin diagnostic \cite{gelman_rubin}. Next, let's look at the statistical results from our chain in Table \href{tab:1mcmc}.
\begin{table}[H]
\centering
        \begin{tabular}{c|c c c |c}
            \hline
            \textbf{Parameter} & \textbf{Mean} & Std &  \textbf{Geweke} & \textbf{Chain Acceptance Rate}\\ 
            \cline{1-5}
            $\alpha$ & 0.779 & 0.134 & 0.895 & \multirow{4}{*}{0.0242} \\
            $\beta$ & 0.0301 & 5.40e-03 & 0.906\\
            $\gamma$ & 0.412 & 0.0871  & 0.905\\
            $\delta$ &  9.95e-03 & 2.30e-03  & 0.902 
            \\\hline
                          \hline
        \end{tabular}
    \caption{Table listing results of the Metropolis chain. Parameter means, standard deviations, and convergence diagnostics (Geweke) are calculated. Based on the Geweke values, the chain has converged for all the parameters.}
    \label{tab:1mcmc}
\end{table}
From \textbf{Table \ref{tab:1mcmc}}, we are most interested in the Geweke diagnostic. For now, it is enough to know that the diagnostic mimics the two-sample test  and compares the means of the first $10\%$ and last $50\%$ of the chain. If these means are similar, it indicates that convergence occurred within the first $10\%$ of the chain's samples \cite{geweke_ppt} \cite{geweke1}. In this implementation, the Geweke value is a ratio of the two means, thus values closer to 1 indicate convergence. While there is no universal threshold for Geweke that concludes convergence, we consider a Geweke value $\geq 0.7$ to be sufficient for convergence. By this standard, the chain has converged for all our parameters and we are confident that the parameters' mean values produce a good prediction of our model (as seen in \textbf{Figure \ref{fig:5mcmc}}). 
\par Finally, we can assess the performance of via the chain's acceptance ratio. Previous literature mathematically justifies that an acceptance rate of around $25\%$ indicates high performance of the chain \cite{convergence} \cite{converge_threshold}. However, it should be cautioned that (as with most claims of universal applications), we cannot rely solely on this diagnostic. We merely present the chain acceptance rate as one mode of investigating chain performance. An acceptance rate of 0.0242, is significantly smaller than the recommended 0.25. This indicates that our algorithm is perhaps not performing very well. A visual assessment of the mixing of the chain in \textbf{Figure \ref{fig:2mcmc}} seems to corroborate this idea. A well-mixed chain is defined as having explored all important regions within its stationary distribution \cite{convergence_mixing}. Visually at each sample, we want to see our chain explore the full range (given by the implementer) of the parameter value, settling around a mean value \cite{convergence_ppt}. In looking at the trace plot for $\alpha$, we see that while the chain changes values at each step, the amount by which parameter values change differs sample to sample. This results in a pronounced increase and decrease of mean (although it does still converge around a single value). In a well-mixed chain (see \textbf{ Figure \ref{fig:7mcmc}}), we would see that parameter values differ by a very similar amount sample to sample.
Other methods for formally assessing mixing are beyond the scope of this paper \cite{convergence_mixing}.
\par The \texttt{mcmcstat} library provides functions to analyze the relationships between the parameters of our model.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_mh_samples.png}
    \caption{Relationships between Lotka-Volterra parameter values per chain sample using the Metropolis MCMC algorithm. There are several obvious relationships between parameters. These correlation will play a role in the algorithm's ability to choose optimal parameter values.}
    \label{fig:3mcmc}
\end{figure}
Recall that the parameter space for this model is 4-dimensional. \textbf{Figure \ref{fig:3mcmc}} illustrates the relationships in our parameter space as more and more values are sampled. We can see that some relationships, like $\alpha \sim \beta$ and $\delta \sim \gamma$, are positive., while others like $\alpha \sim \gamma$ and $\alpha \sim \delta$ appear to have a strong negative relationship. These relationships are a result of the model and the data, however, they do impact the sampling procedure as the positive and negative relationships make it difficult to determine unique parameter sets. While we will not explore this idea of \emph{parameter identifiability} in this tutorial, we encourage the reader to consult \cite{smithCh8}. Briefly, parameter identifiability quantifies how parameter values may be correlated but can still be uniquely determined by the model \cite{smithCh8}.
\subsubsection{Working with the distributions}
\par Now let's see how we can determine a posterior distribution for our parameters:
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_mh_den.png}
    \caption{Posterior density distributions for each Lotka-Volterra model parameter using the Metropolis MCMC algorithm. The distribution for $\alpha$ is noticeably not smooth at its peak. This illustrates the algorithm's inability to find the optimal mean value for $\alpha$. Additionally, this non-smoothness is reflected in the lower Geweke value, which although indicates convergence, does not indicate such complete convergence as the other parameters.}
    \label{fig:4mcmc}
\end{figure}
By collecting the accepted values for each parameter, we can fit distributions such as those in \textbf{Figure \ref{fig:4mcmc}}. While we cannot definitively categorize these distributions visually, we can see that at least $\gamma$ and $\delta$ resemble some a familiar distribution, namely a lognormal distribution. It is more difficult to categorize $\alpha$ although $\beta$ appears to tend toward a normal distribution. It is useful to visualize these distributions, but they may not be directly useful. However, we can calculate their means that may be used in computations. Additionally, we make note of the relative ``bumpiness" of the peak in $\alpha$'s PDF. This indicates that the algorithm may have had difficulty in pinpointing the optimal mean value. The lack of smoothness is also reflected in $\alpha$'s lower Geweke value; although we still conclude convergence of the chain for $\alpha$, the chain did not demonstrate the confidence of convergence as it did for the remaining 3 parameters. Next we visualize some predictions of our model using the chain samples.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/final_mh_modpred.png}
    \caption{Predicted hare and lynx populations using parameter values found using Metropolis MCMC. Black lines indicate the mean model prediction; gray area indicates 95$\%$ probability limits for new observations; blue points indicate original raw hare and lynx population data. For both hare and lynx populations, the Metropolis parameterization is unable to fully capture the irregular peaks in populations that occur from around 1840 to 1910. Instead, we see a symmetric periodic function for both population predictions.}
    \label{fig:5mcmc}
\end{figure}
From \textbf{Figure \ref{fig:5mcmc}}, we can get a visual sense of how well our sampled parameter values predict the raw data given our model. In the predicted lynx population, all of the raw data falls within our $95\%$ probability range, which tells us our predictions are doing a good job of capturing the data. In the hare population, most of the raw data falls within that $95\%$ range, although few points are not. For both model predictions, we would like to see a tighter $95\%$ range which would indicate that our algorithm settled tightly around an ideal parameter value rather than a large range. We see that for both the hare and lynx populations, some of the $95\%$ range falls below zero which is not biologically possible. The 95\% probability ranges help us to determine how well a majority of our sampled parameter sets capture the data. However in practice, we are most interested in the prediction that uses the mean parameter values as we are likely to only want to use a single set of parameter values in future models.
\section{Delayed Rejection Adaptive Metropolis} \label{Delayed_Rejection_Adaptive_Metropolis}
There are many variations of MCMC methods that can be used to parameterize biological systems, each with their own benefits. We have chosen to describe the delayed rejection adaptive Metropolis (DRAM) MCMC method to compare with the Metropolis MCMC algorithm \cite{DRAM1}. As its name suggests, DRAM builds upon several of the MCMC algorithms namely adaptive Metropolis (AM) and delayed rejection (DR) and is often used in order to allow for better adaptation of the sampling chain as time goes on \cite{DRAM1}. Like most MCMC methods, DRAM requires initialization of proposal, likelihood, and prior distributions. However, while the proposal distribution of Metropolis MCMC is assumed (via a covariance matrix) given some \emph{a priori} information about parameter values and variability, in adaptive methods such as DRAM, posterior information learned during the progression of the algorithm is immediately incorporated and the algorithm adjusted. In order to understand the DRAM algorithm, it is useful to begin with its two parts.
\subsection{Adaptive Metropolis}
The adaptive Metropolis method is an optimization of of simpler MCMC algorithms as it allows the algorithm to move quickly through parameter space of low probability \cite{collis}, \cite{adaptive_andrieu}, \cite{adaptive_andrieu}. The adaptive algorithm does this by updating its proposal distribution as sampling occurs thus creating a more informed pool from which candidates are drawn. The adaptive Metropolis algorithm proceeds as follows:
\begin{tcolorbox} \label{box:am}
\textbf{\underline{Adaptive Metropolis Algorithm (with an uninformative prior)}}
\begin{enumerate}
\item Set number of chain elements, $N$, and number of candidates to sample before updating the proposal distribution, $k_0$
    \item Determine an initial parameter guess $\theta^0 = argmin_q \sum_{i=1}^{n}[M_i - f_i(\theta)]^2]$
    \item Set $SS_{\theta^0} = \sum_{i = 1}^{n}[y_i - f_i(\theta^0)]^2$ (for likelihood)
    \item Compute an initial variance estimate $s_0^2 = \frac{SS_{\theta^0}}{n-p}$ ($n =$ number of data points, $p = $ number of parameters)
    \item Construct an initial proposal covariance matrix $V_0$ 
    \item For each iteration of the chain, $k = 1,...,N$
    \begin{enumerate}
        \item Sample $z \sim N(0,I_p)$
        \item Construct candidate $\theta^* = \theta^{k-1}+ V_0z_k$
        \item Compute $SS_{\theta^*} = \sum_{i = 1}^{n}[y_i - f_i(\theta^*)]^2$ (likelihood sum of squares)
        \item Compute acceptance criterion
            \begin{center}
                $\alpha(\theta^* | \theta^{k-1}) = min(1, e^{-[SS_{\theta^*}-SS_{\theta^{k-1}}/2s_{k-1}^2]})$
            \end{center}
        \item Accept $\theta^*$ with a probability 1 if $\alpha \geq 1$ and accept it with probability $\alpha$ if $\alpha < 1$.
        \begin{itemize}
            \item If $\theta^*$ is accepted
            \begin{center}
                $\theta^k = \theta^*$, $SS_{\theta^k} = SS_{\theta^*}$
            \end{center}
            \item Else
            \begin{center}
                $\theta^k = \theta^{k-1}$, $SS_{\theta^k} = SS_{\theta^{k-1}}$
            \end{center}
        \end{itemize}
        \item Update $s_k^2 = \frac{SS_{\theta^k}}{n-p}$
    \end{enumerate}
    \begin{tcolorbox}[colback=red!5,colframe=red!75!black,title=Adaptive Step]
    \item If $k = k_0$ adaptation commences: the initial $V_0$ is updated to the covariance matrix, $V_{k}$ \label{step:7adapt}
    \begin{center}
       $V_{k} = s_{p}cov(\theta^{0},\theta^{1},...,\theta^{k-1}) + \epsilon I_{p}$
    \end{center}
    \end{tcolorbox}
    
\end{enumerate}
\emph{Based on Smith (2014) Algorithm 8.8}
\end{tcolorbox}
\par We want to choose $k_0$ to balance a mixing with sufficient diversity of points to ensure a non-singular covariance matrix. Shorter adaptation intervals tend to produce better mixing and higher acceptance ratios \cite{convergence_mixing} and thus, the chain is more responsive to new data from parameter space not previously explored. In practice, $k_0$ is often 100 \cite{smithCh8}. 
\par In \textbf{step \ref{step:7adapt}} of this algorithm, $s_{p}$ is a design parameter that depends on the dimension ($p$) of the parameter space; a common choice is $s_{p} = 2.38^{2}/p$. The term $\epsilon I_{p}$ refers to an identity matrix of dimension $p$-by-$p$ (to ensure $V_{k}$ is positive definite). Often, $\epsilon = 0$ \cite{smithCh8}.
\par While steps 1-6 are directly adapted from the Metropolis MCMC algorithm, \textbf{step 7} in the above algorithm is the new adaptive step that allows the algorithm to traverse parameter space of lower probability efficiently.
\subsection{Delayed Rejection}
\par The delayed rejection MCMC improves the efficiency of other MCMC methods by increasing the increasing transition probability of parameters leading to improvement in chain mixing \cite{trias2009delayed}. In the standard Metropolis algorithm, when a candidate parameter set $\theta^*$ is rejected (with its prescribed acceptance ratio $\alpha$), the current step parameter set, $\theta^{k-1}$, is retained and $\theta^*$ is discarded before choosing the next sample. In the \emph{delayed rejection} (DR) algorithm, when $\theta^*$ is rejected, alternative candidates $\theta^{*j}$ are constructed and considered instead of immediately reverting back to $\theta^{k-1}$. We can specify the number of alternatives our algorithm will propose before moving on to the next iteration of the chain. By sampling multiple candidates under the same sampling conditions (recall \textbf{step \ref{step:6met}g} of the Metropolis algorithm) we allow the algorithm to consider parameter space with lower probability that, in the Metropolis algorithm, may have been omitted. Additionally, these alternative candidates prevent the algorithm from getting stuck in local maxima or minima. Loosely this works as follows: when we accept a candidate parameter, its values become the basis of constructing the next proposed candidate (recall \textbf{steps \ref{step:6met}a} and \textbf{\ref{step:6met}b} of the Metropolis algorithm). Therefore, the next time we reject a candidate, the subsequent candidate must be constructed using only the same information as the most recently accepted parameter set. This is computationally inefficient as we have already searched this particular parameter space, yet we are forced to draw again from the same space and in effect, we have not explored anything new. When this immediate rejection process is compounded, we may encounter long periods in which we propose many candidates only using a single set of parameter values, thus we are not exploring the whole parameter space and run the risk of staying in local maxima or minima.
\par In order to work with alternative candidates, we must redefine the acceptance criterion, $\alpha$. We follow an explanation from \cite{smithCh8}.\\
For example, $\theta^{*2}$, a second-stage candidate, is chosen using proposal function
\begin{equation} \label{eq:17mcmc}
J_{*2}(\theta^{*2}|\theta^{k-1},\theta^*) \sim N(\theta^{k-1}, \gamma_2^2V)
\end{equation} 
where $V$ is the covariance matrix informing the proposal distribution. $J_{*2}(\theta^{*2}|\theta^{k-1},\theta^*)$ indicates that we propose $\theta^{*2}$ having started at $\theta^{k-1}$ and rejected $\theta^*$. Finally, $\gamma_2 < 1$ tunes the second-stage proposal function and increases mixing \cite{smithCh8}. The acceptance criteria for the second-stage candidate thus is\\
\begin{equation} \label{eq:18mcmc}
\alpha_{*2}(\theta^{*2}|\theta^{k-1}, \theta^*) = min(1, \frac{P(\theta^{*2}|M)J(\theta^*|
    \theta^{*2})[1-\alpha(\theta^*|\theta^{*2})]}{P(\theta^{k-1}|M)J(\theta^*|\theta^{k-1})[1-\alpha(\theta^*|\theta^{k-1})]})
\end{equation}
\begin{tcolorbox} 
\textbf{\underline{Delayed Rejection Algorithm (with an uninformative prior)}}
\begin{enumerate}

\item Set number of chain elements, $N$, choose number of alternatives, $n_{alt}$
    \item Determine an initial parameter guess $\theta^0 = argmin_q \sum_{i=1}^{n}[M_i - f_i(\theta)]^2]$
    \item Set $SS_{\theta^0} = \sum_{i = 1}^{n}[y_i - f_i(\theta^0)]^2$ (for likelihood)
    \item Compute an initial variance estimate $s_0^2 = \frac{SS_{\theta^0}}{n-p}$ ($n =$ number of data points, $p = $ number of parameters)
    \item Construct a proposal covariance matrix $V$ 
    \item For each iteration of the chain, $k = 1,...,N$
    \begin{enumerate}
        \item Sample $z \sim N(0,I_p)$ 
        \item Construct candidate $\theta^* = \theta^{k-1}+ V_0z_k$
        
        \item Compute $SS_{\theta^*} = \sum_{i = 1}^{n}[y_i - f_i(\theta^*)]^2$ (likelihood sum of squares)
        \item Compute acceptance criterion
            \begin{center}
                $\alpha(\theta^* | \theta^{k-1}) = min(1, e^{-[SS_{\theta^*}-SS_{\theta^{k-1}}/2s_{k-1}^2]})$
            \end{center}
        \item Accept $\theta^*$ with a probability 1 if $\alpha \geq 1$ and accept it with probability $\alpha$ if $\alpha < 1$.
        \begin{enumerate}
            \item If $\theta^*$ is accepted, proceed to next sample
            \begin{center}
                $\theta^k = \theta^*$, $SS_{\theta^k} = SS_{\theta^*}$
            \end{center}
            \begin{tcolorbox}[colback=red!5,colframe=red!75!black,title=Delayed Rejection]
        
            \item Else enter \textbf{delayed rejection process} while $n_i \leq n_{alt}$
            \begin{enumerate}
                \item Set design parameter $\gamma_2 = \frac{1}{5}$
                \item Sample $z \sim N(0,I_p)$ 
                \item Construct j-stage alternative $\theta^{*j} = \theta^{k-1} + \gamma_2Vz$
                \item Compute acceptance criterion
                \begin{center}
                  $\alpha_{*j}(\theta^{*j}|\theta^{k-1}, \theta^*) = min(1, \frac{P(\theta^{*j}|M)J(\theta^*|
    \theta^{*j})[1-\alpha(\theta^*|\theta^{*2})]}{P(\theta^{k-1}|M)J(\theta^*|\theta^{k-1})[1-\alpha(\theta^*|\theta^{k-1})]})$
                \end{center}
                \item Accept $\theta^{*j}$ with a probability 1 if $\alpha_{*j} \geq 1$ and accept with probability $\alpha_{*j}$ if $\alpha_{*j} < 1$.
            \end{enumerate}
            \end{tcolorbox}
        \end{enumerate}
        \item Update $s_k^2 = \frac{SS_{\theta^k}}{n-p}$
    \end{enumerate}
\end{enumerate}
\emph{Based on Smith (2014) Algorithm 8.8}
\end{tcolorbox}
\par Now we have an understanding of both the delayed rejection and adaptive Metropolis MCMC algorithms, we can construct the final DRAM algorithm. We will do this in the following section by using steps 1-6 of the Metropolis algorithm as a foundation and incorporating step 7 of the adaptive Metropolis algorithm and step 6e(ii) of the delayed rejection algorithm.
\subsection{Constructing the DRAM Algorithm}
Now that we have the basis for the two components of the delayed rejection adaptive Metropolis algorithm, all that is left to do is merge them. Using the foundation of the Metropolis algorithm, we add an adaptive step and a delayed rejection process. In the DRAM algorithm, the adaptive Metropolis and delayed rejection work together: AM updates the proposal via previously accepted candidates and the covariance matrix and DR alters the proposal function to improve mixing.
\begin{tcolorbox}
\textbf{\underline{The DRAM Algorithm (with an uninformative prior)}} 
\begin{enumerate}
\item Set number of chain elements, $N$,adaptive chain length, $k_0$, and number of alternatives, $n_{alt}$
    \item Determine an initial parameter guess $\theta^0 = argmin_q \sum_{i=1}^{n}[M_i - f_i(\theta)]^2]$
    \item Set $SS_{\theta^0} = \sum_{i = 1}^{n}[y_i - f_i(\theta^0)]^2$ (for likelihood)
    \item Compute an initial variance estimate $s_0^2 = \frac{SS_{\theta^0}}{n-p}$ ($n =$ number of data points, $p = $ number of parameters)
    \item Construct an initial covariance matrix $V_0$ 
    \item For each iteration of the chain, $k = 1,...,N$
    \begin{enumerate}
        \item Sample $z \sim N(0,I_p)$
        \item Construct candidate $\theta^* = \theta^{k-1}+ V_0z_k$
        \item Compute $SS_{\theta^*} = \sum_{i = 1}^{n}[y_i - f_i(\theta^*)]^2$ (likelihood sum of squares)
        \item Compute acceptance criterion
            \begin{center}
                $\alpha(\theta^* | \theta^{k-1}) = min(1, e^{-[SS_{\theta^*}-SS_{\theta^{k-1}}/2s_{k-1}^2]})$
            \end{center}
        \item Accept $\theta^*$ with a probability 1 if $\alpha \geq 1$ and accept it with probability $\alpha$ if $\alpha < 1$.
        \begin{tcolorbox}[colback=red!5,colframe=red!75!black,title=DRAM Step]
        \begin{enumerate}
            \item If $\theta^*$ is accepted, proceed to next sample
            \begin{center}
                $\theta^k = \theta^*$, $SS_{\theta^k} = SS_{\theta^*}$
            \end{center}
            \item Else enter \textbf{delayed rejection process} while $n_i \leq n_{alt}$
            \begin{enumerate}
                \item Set design parameter $\gamma_2 = \frac{1}{5}$
                \item Sample $z \sim N(0,I_p)$ 
                \item Construct j-stage alternative $\theta^{*j} = \theta^{k-1} + \gamma_2Vz$
                \item Compute acceptance criterion
                \begin{center}
                  $\alpha_{*j}(\theta^{*j}|\theta^{k-1}, \theta^*) = min(1, \frac{P(\theta^{*j}|M)J(\theta^*|
    \theta^{*j})[1-\alpha(\theta^*|\theta^{*2})]}{P(\theta^{k-1}|M)J(\theta^*|\theta^{k-1})[1-\alpha(\theta^*|\theta^{k-1})]})$
                \end{center}
                \item Accept $\theta^{*j}$ with a probability 1 if $\alpha_{*j} \geq 1$ and accept with probability $\alpha_{*j}$ if $\alpha_{*j} < 1$.
            \end{enumerate}
            
        \end{enumerate}
        \item If $k = k_0$ adaptation commences: the initial $V_0$ is updated to the covariance matrix, $V_{k}$
       
        \begin{center}
            $V_{k} = s_{p}cov(\theta^{0},\theta^{1},...,\theta^{k-1}) + \epsilon I_{p}$
        \end{center}
        \end{tcolorbox}
        \item Update $s_k^2 = \frac{SS_{\theta^k}}{n-p}$
        
    \end{enumerate}
    
\end{enumerate}
\emph{Based on Smith (2014) Algorithms 8.8 and 8.10}
\end{tcolorbox}


\subsection{Parameterizing Lotka-Volterra}
As with the Metropolis MCMC, DRAM was used to parameterize the Lotka-Volterra system. We implemented prior, likelihood, and proposal distributions identical to those used in the Metropolis parameterization. The number of iterations was also held constant. The adaptive interval $k_0$ was defined to be 100, a common default in DRAM. Finally, while DRAM allows for any number of alternative candidates to be proposed, 2 alternates were used. Just as in the Metropolis parameterization, we first visualize the burn-in and sampled chains.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_dram_burninchain.png}
    \caption{Burn-in chain (10,000 samples) for the DRAM MCMC parameterization of the Lotka-Volterra model. Each line shows the sampled parameter values. This figure illustrates the movement of the Markov chain as it samples parameters with the goal of finding the most likely range of values. As expected, the chain has not converged for all the parameters yet.}
    \label{fig:6mcmc} 
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_dram_chain.png}
    \caption{Sampling chain (500,000 samples) for the DRAM MCMC parameterization of the Lotka-Volterra model. Each line shows the sampled parameter values. This figure visualizes each parameter value that has been sampled and accepted that will be used to build parameter PDFs. This chain visualization shows a ``fuzzy caterpillar" sampling pattern indicative of a well-mixed chain.}
    \label{fig:7mcmc}
\end{figure}
\textbf{Figure \ref{eq:7mcmc}} shows the chain's exploration of the parameter space during the burn-in period (10,000 samples). From a preliminary visual analysis of this chain, we can see that $\alpha$, $\beta$, and $\delta$ seem to find their steady states fairly quickly ($<$ 2,000 samples). Additionally, $\gamma$ seems to trend toward its optimal value range more immediately than in the Metropolis algorithm (\textbf{Figure \ref{fig:1mcmc}}). From 0 to around 9,000 samples, $\gamma$ generally trends downward until it hits a value range of $0.3$ to $0.2$. In \textbf{Figure \ref{fig:7mcmc}}, we illustrate the final 500,000 values that our algorithm sampled. From a visual perspective, this chain appears to demonstrate good mixing as the chain appears to have settled in a steady state for each parameter. This is evidenced by the lack of a ``wave" pattern that we saw in \textbf{Figure \ref{fig:2mcmc}} and thus, a lack of increasing or decreasing trends of parameter values. For instance, $\alpha$ appears to move around 0.8 while $\gamma$ settles around 0.4. Statisticians have often referred to a well-mixed plot as resembling a ``fuzzy caterpillar", that due to its dense and somewhat spiked samples, but relatively constant mean, the values of the chain are no longer changing and are therefore in a steady state \cite{fuzzy_caterpillar}.
\par Next, let's look at the statistical results from our chain in Table 2.
\begin{table}[H]
\centering
        \begin{tabular}{c|c c c |c}
            \hline
            \textbf{Parameter} & \textbf{Mean} &  \textbf{Std} & \textbf{ Geweke} &\textbf{Chain Acceptance Rate}\\ 
            \cline{1-5}
            $\alpha$ & 0.787 & 0.139 & 0.983 & \multirow{4}{*}{0.241} \\
            $\beta$ & 0.0303 & 5.58e-03 & 0.989\\
            $\gamma$ & 0.407 & 0.0908 & 0.931\\
            $\delta$ &  9.83e-03 & 2.39e-03 & 0.933
             \\\hline
                          \hline
                           
        \end{tabular}
    \caption{Table listing results of the DRAM chain. Parameter means, standard deviations, and convergence diagnostics (Geweke) are calculated. Based on the Geweke values, we conclude that the chain has converged for all the parameters.}
    \label{tab:2mcmc}
\end{table}
We can use the parameter means and standard deviations to find the optimal range of parameter values for this model. Using a Geweke $\geq 0.7$ to indicate convergence, the chain has converged for all our parameters and we are confident that the parameters' mean values produce a good prediction of our model (as seen in \textbf{Figure \ref{fig:10mcmc}}). Lastly, we look at the chain's acceptance ratio 
\par We look again to the chain's acceptance rate and the visual assessment of mixing to help us analyze the chain's performance. In \textbf{Table \ref{tab:2mcmc}}, we see that the acceptance rate is very close to the proposed indication of good performance, $25\%$ acceptance. This leads us to believe that our chain has done a pretty good job. We further validate this belief by looking at the trace plots of the chains in \textbf{Figure \ref{fig:7mcmc}}. \textbf{Figure \ref{fig:7mcmc}} shows us that our chain is well-mixed for each of our parameters as it appears our chain has reached a steady-state for each parameter value. 
\par Let's look at the relationships between parameters as the chain samples.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_dram_samples.png}
    \caption{Relationships between Lotka-Volterra parameter values per chain sample using the DRAM MCMC algorithm. We see some distinct postive and negative relationships between parameter values. Recalling the idea of \textit{parameter identifiability}, this may have an impact on algorithm's sampling ability.}
    \label{fig:8mcmc}
\end{figure}
In \textbf{Figure \ref{fig:8mcmc}}, we illustrate the relationships between parameter values. We see the same positive relationships in $\alpha \sim \beta$ and $\delta \sim \gamma$ and the same negative relationships in $\alpha \sim \gamma$, $\alpha \sim \delta$, $\gamma \sim \beta$, and $\delta \sim \beta$. \\
\subsubsection{Working with the distributions}
We visualize the posterior PDFs for the system's parameters:
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/met_lv_final/final_dram_den.png}
    \caption{Posterior density distribution for each Lotka-Volterra parameter using the DRAM MCMC algorithm. Unlike the PDFs produced by the Metropolis MCMC algorithm, these PDFs appear fairly smooth. This indicates that the algorithm was more successful at finding global maxima.}
    \label{fig:9mcmc}
\end{figure}
We will perform a more thorough comparison of the two MCMC algorithms, but for now, we can see that like the Metropolis MCMC algorithm, we produce posterior density functions for each parameter in our model. Similarly to the Metropolis PDFs, we cannot strictly classify these distributions as normal. Instead, we can see how these sampled parameter sets perform against our original data.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/final_dram_modpred.png}
    \caption{Predicted hare and lynx populations using parameter values found using DRAM MCMC. Black lines indicate the mean model prediction; gray area indicates 95$\%$ probability limits for new observations; blue points indicate original raw hare and lynx population data. We can see that the prediction is having difficulty capturing the beginning of the original data (1840 to \sim 1900). However, the prediction appears to capture the end behavior fairly well for both hare and lynx populations.}
    \label{fig:10mcmc}
\end{figure}
\textbf{Figure \ref{fig:10mcmc}} shows us a $95\%$ probability limit for model predictions using the parameter sets sampled during DRAM. Ideally, we would like to see a smaller range in these prediction. The line in black indicates the model's prediction given the "best" set of parameters. While our probability range appears wide, particularly for the lynx population, we note that the best predicted model (black line) fits the original data pretty well, especially toward the end of the time span.
\section{Comparing Metropolis and DRAM MCMC Methods} \label{Comparing Metropolis_and_DRAM_MCMC_Methods}
Now we have seen two MCMC methods that we can use to parameterize a biological ODE model. Before moving on to parameterize the Type 1 Diabetes model, it is useful to compare results of these two methods to see if one does a "better" job at parameterization.
\par Let's first compare the sampling chains
\begin{figure}[H]
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{MCMC_figs/met_lv_final/final_mh_chain.png}
  \caption{Metropolis MCMC sample chain.}
  \label{fig:11amcmcm}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{MCMC_figs/met_lv_final/final_dram_chain.png}
  \caption{DRAM MCMC sample chain}
  \label{fig:11bmcmcm} 
\end{subfigure}
\caption{Comparing visual results of the sample chains from Metropolis and DRAM MCMC. The DRAM chain exhibits better mixing as it has the distinct ``fuzzy caterpillar" pattern.}
\label{fig:11mcmc}
\end{figure}
As we mentioned earlier, the ideal chain would be ``fuzzy catepillar-like" and we see this illustrated well in the DRAM algorithm, Figure \textbf{\ref{fig:11bmcmcm}}. It seems that the Metropolis chain has not done as good a job of sampling the parameter space, \textbf{Figure \ref{fig:11amcmcm}}. This so far this suggests that the DRAM is doing a better job of exploring the sampling space.
\par Next let's compare the computed results of these chains
\begin{table}[H]
\centering
        \begin{tabular}{c | c | c c c c}
            \cline{2-6}
            & \textbf{Algorithm} &  \textbf{$\alpha$} & \textbf{ $\beta$} &  \textbf{$\gamma$} & \textbf{$\delta$}\\ 
            \cline{1-6}
            
            \multirow{2}{*}{\textbf{Mean}} & Met & 0.779 & 0.0301 & 0.412 & 9.95e-03 \\
            & DRAM & 0.787 & 0.0303 & 0.407 & 9.83e-03\\ \hline
            \multirow{2}{*}{\textbf{Std}} & Met &  0.134 & 5.40e-03 & 0.0871 & 2.30e-03 \\
            & DRAM & 0.139 & 5.58e-03 & 0.0908 & 2.39e-03\\ \hline
            \multirow{2}{*}{\textbf{Geweke}} & Met & 0.895 & 0.906 & 0.905 & 0.902 \\
            & DRAM & 0.983 & 0.989 & 0.931 & 0.933\\ \hline
            \multirow{2}{*}{\textbf{Chain Acceptance Rate}} & Met & \multicolumn{4}{c}{0.0242}\\
            & DRAM & \multicolumn{4}{c}{0.241}
             \\\hline
             \hline
        \end{tabular}
    \caption{Comparison of the results of the Metropolis and DRAM MCMC chains per parameter. There do not appear to be any significant differences in parameter values between the two algorithms. The only significant difference between the Geweke values occurs for $\alpha$. The DRAM appears to reach a better convergence than the Metropolis algorithm. The DRAM chain acceptance rate is significantly closer to the indicative threshold of 25\%. We do not yet discern any significant differences between the performances of each chain.}
    \label{tab:3mcmc}
\end{table}
We do not see any significant differences in individual parameter values between the two algorithms. We note a signnificant difference in the Geweke values of the parameter $\alpha$, the DRAM algorithm produced a higher convergence diagnostic. This may help explain the visual difference between the PDFs for $\alpha$. In \textbf{Figure \ref{fig:4mcmc}} we saw a lack of smoothness, while in \textbf{Figure \ref{fig:9mcmc}} we did see a more smooth distribution. Lastly we note the difference in chain acceptance rates. While not a perfect indicator of chain performance, we note that the DRAM algorithm's chain acceptance rate is much closer to the general threshold of 25\% acceptance. 
\begin{figure}[H]
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{MCMC_figs/met_lv_final/mh_dram_paramComp1.png}
  \caption{Comparison of means for $\alpha$ (left) and $\gamma$ (right).}
  \label{fig:12amcmcm}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{MCMC_figs/met_lv_final/mh_dram_paramComp2.png}
  \caption{Comparison of means for $\beta$ (left) and $\delta$ (right).}
  \label{fig:12bmcmcm} 
\end{subfigure}
\caption{Comparing parameter means between the Metropolis and DRAM algorithms. Error bars were calculated using 1 standard deviation from Table 3. We can see that no parameter mean values are significantly different.}
\label{fig:12mcmc}
\end{figure}
From both \textbf{Table \ref{tab:3mcmc}} and \textbf{Figure \ref{fig:12mcmc}}, we see that both algorithms are producing very similar values for each of the parameters. \textbf{Figure \ref{fig:12mcmc}} shows us that the means produced by each algorithm are not significantly different. This tells us both algorithms are finding the same global maxima ranges in the parameter space. In order to truly compare the the performance of these two algorithms, we can compare the convergences and chain acceptance rates. While for both algorithms, we consider the chains to have converged for all parameters (Geweke $\geq 0.7$), we see that overall, the DRAM algorithm has Geweke values closer to 1. We do not have a definite reasoning for why there would be higher Geweke values for DRAM might be greater than those of the Metropolis MCMC, but we speculate that it is perhaps due to the overall sampling shapes that we saw in \textbf{Figure \ref{fig:11mcmc}}. With a more uniformly incremented selection of parameters, as in the DRAM algorithm, when we take the means of the first 10$\%$ and last $50\%$ of the chain, they are more likely to be very similar. On the other hand, in the Metropolis algorithm, since there is less uniformity when choosing the increments between samples, these same means are less likely to be so similar. And we can see this reflected in the difference in Geweke values. Lastly, we briefly compare the chain acceptance rates. As we mentioned before, a very general threshold for acceptance rates is around $25\%$ and is an indicator that the chain has converged and performed well. We more formally validate chain performance using the Geweke diagnostics that both chains have converged, but since the chain acceptance rate for Metropolis MCMC is significantly less than 0.25, we wonder if our algorithm is not performing as well as the DRAM algorithm.
\par We note that our statement of better performance with the DRAM algorithm is only in the context of our tutorial - that is with our specific model, burn-in period, total number of samples, likelihood functions, etc. Although we have not explored it here, increasing the number samples or tuning other parts of the Metropolis algorithm might in fact produce better results than the DRAM algorithm. The purpose of these tutorials is to help the user become more familiar with these two algorithms so that he or she can make an informed decision in choosing which algorithm to use.
\par Finally, we compare the predicted models of each algorithm.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_mh_meanpredComp.png}
    \caption{Comparing mean predictions of the Metropolis and DRAM MCMC methods. Overlaid in black is the original raw hare and lynx data. Both predictions appear to capture the end behavior of the raw data, but fail to capture the starting behavior. It is difficult to visually determine which algorithm produces a better prediction.}
    \label{fig:13mcmc}
\end{figure}
While our predictions do not perfectly capture the original data, the period of each prediction is very similar to that of the original data. However, we do note some differences between the original data and each algorithm's prediction. In the lynx populations, both algorithms predict an initial decrease in population while the raw data has an increase instead. Both algorithms have a consistent period and amplitude while the raw data for both hare and lynx populations does not, thus both predictions miss a significant amount of the raw data from 1840 to around 1900. However, when the raw data becomes more consistent, around 1910 to 1940, with less variation in the period and amplitude, both predictions are able to capture these data points better. It is interesting to note that for the hare population, the Metropolis function predicts a periodic function with a greater amplitude than the DRAM algorithm and vice versa for the lynx population. But in both population predictions, they have very similar periods. This could be a result of the way the MATLAB ODE solver evaluates our particular model.
\par While we have thus far presented several techniques for assessing algorithm performance, visual assessment of trace plots, the Geweke diagnostic, and chain acceptance rate, we base our evaluation more heavily on determining whether our algorithm has produced a prediction that captures the raw data well. In \textbf{Figure \ref{fig:13mcmc}}, we believe that both our algorithms have satisfactorily captured the data. We will quantify the performance more formally using root mean squared error in \textbf{Table \ref{tab:4mcmc}}.
\begin{table}[H]
\centering
        \begin{tabular}{c | c c}
            \cline{1-3}
            \textbf{MCMC Algorithm}  &\textbf{Hare} & \textbf{Lynx}\\
            \hline
            Metropolis & 18.16 & 31.30\\
            DRAM & 18.03 & 31.66
             \\\hline
            \hline
        \end{tabular}
    \caption{Formal comparison of the Metropolis and DRAM MCMC methods on the Lotka-Volterra system using root mean squared error (RMSE). Based on RMSE scores, there is no significant difference between the two predictions. We conclude that both}
    \label{tab:4mcmc}
\end{table}
\textbf{Figure \ref{fig:13mcmc}} showed us that the two algorithms performed very similarly and \textbf{Table \ref{tab:4mcmc}} confirms this. A perfect fit of the data by the prediction would produced an RMSE score of 0. While it is difficult to formally determine an RMSE threshold for prediction performance, we consider the scores in \textbf{Table \ref{tab:4mcmc}} to indicate that the data was captured fairly well. In general, we would say that an RMSE score of $>$100 would indicate poor performance. While DRAM appears to perform better on the hare population prediction and the Metropolis appears to perform better on the lynx population prediction, there is no significant difference between the RMSE scores. Both \textbf{Figure \ref{fig:13mcmc}} and \textbf{Table \ref{tab:4mcmc}} suggest that both the DRAM and Metropolis MCMC algorithms can perform comparably well on this Lotka-Volterra system.
\par Perhaps it is due to the simplicity of the Lotka-Volterra model and relatively low-dimensional parameter space, that we are able to produce fairly similar predictions. However, taking note of the discrepancies between the two algorithms that we discussed early, we might assume that as a model becomes more complex and the parameter space increases exponentially (recall the curse of dimensionality), these differences may also increase. Thus, as we will parameterize the Type 1 Diabetes model in the next section, we choose to do so with the DRAM MCMC algorithm. So far this algorithm has demonstrated sufficient chain sampling (\textbf{Figure \ref{fig:11bmcmcm}}), convergence (\textbf{Table \ref{tab:3mcmc}}), and smooth distributions (\textbf{Figure \ref{fig:9mcmc}}).

\section{Parameterizing the Type 1 Diabetes Model with DRAM} \label{Parameterizing_T1D_DRAM}
We preface this section by saying that the implementation of the DRAM algorithm for the Type 1 Diabetes model this is still in the process of being fine-tuned and improved. Therefore, we advise the reader to read our code and comments thoroughly and to analyze our results with some caution and skepticism.
\par We consider 10 parameters in this model: the UKF's 7 highly variable (vary $> 1\%$ parameters) and 3 eta parameters. For reasons discussed in section 7.1, we could not parameterize all 53 parameters in the T1D ODE system. Thus we carefully chose parameters that we determined had the greatest impact on the system. The UKF algorithm found 7 parameters that seemed to vary more greatly than the others. We know from our advisors and the Shtylla et al. 2019 paper, that the eta parameters, $\alpha_{\eta}$, $\beta_{\eta}$, and $\eta$ had a great impact on diabetes onset time. Lastly, we ran our algorithm on the model for NOD mice with the apoptotic $\beta$-cell wave on. We choose these settings because all the mice in the Li et al study developed diabetes. A NOD mouse with an apoptotic $\beta$-cell wave are the biologically modelled conditions under which diabetes will occur \cite{shtylla2019mathematical}. 
\par Similar to Lotka-Volterra parameterization, we assume a Gaussian likelihood function in log base e. Thus, the user determines a sum of squares between the model given parameter values and the original data. This sum of squares is then used to construct the acceptance criterion
\begin{equation} \label{eq:19mcmc}
lnP(D|\theta, M) = \sum_{k=1}^{N}lnP(y_k|x_k,\theta,M) = \sum_{k=1}^N SS_\theta 
\end{equation}
 We also again adopt a log-uniform prior
\begin{equation} \label{eq:20mcmc}
lnP(\theta|M) = 0
\end{equation}
The proposal distribution is determined for us in the MATLAB function \texttt{mcmcrun} using a covariance matrix. The acceptance criteria according to the \texttt{mcmcstat} library is defined as
\begin{equation} \label{eq:21mcmc}
\alpha = min(1, e^{ \lbrack {-0.5(\frac{\sum (SS_{\theta^*}-SS_{\theta^{k-1}})}{\sigma^2} + prior^*-prior^{k-1})} \rbrack}) 
\end{equation}
and thus with our assumptions simplifies to 
\begin{equation} \label{eq:22mcmc}
\alpha = min(1, e^{[ {-0.5(\frac{\sum (SS_{\theta^*}-SS_{\theta^{k-1}})}{\sigma^2}]}})
\end{equation}
Lastly, we initialize starting values and ranges for our parameters.
With all of these assumptions and initializations, we can run the DRAM MCMC algorithm and produce PDFs for each of our parameters.
\par We ran the DRAM algorithm on 4 sets of data. The first is the average acute Li mouse data that was described in the Section Problem Set Up. For comparison with this data set and UKF predictions, we also ran our algorithm on a single mouse's data set. Mouse 6 is an example of an acute mouse that we chose because of its relatively large number of data points. Lastly, we ran the algorithm using Mouse 3 and 11 (individual runs). We had visually determined that these two mice had significantly different diabetes onset times and we were interested in exploring how the algorithm's prediction would shift with this shift in onset time. 
\par In the following sections, we analyze the results of running the DRAM algorithm on the averaged data and Mouse 6 data using techniques we developed while parameterizing the Lotka-Volterra system.
\subsection{Averaged Li data}
\subsubsection{Analyzing the chain}
Before jumping straight into using the results of the DRAM algorithm, we want to look at our chain for information about the algorithm's performance. We begin by looking at the trace plots of the chain for each of the parameters. We performed a burn-in period of 1,000 samples, but we only present the trace plots of the post-burn-in chain.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/jul10_avg_run1(noIC)_acute_NOD_waveOn_lietal_traceplots.png}
    \caption{Trace plots of the sampling chain (10,000 samples) for the DRAM MCMC parameterization of the Type 1 Diabetes model on averaged Li data. Chains for each parameter are plotted separately. There are examples of good and bad chain mixing. e1 and e2 exhibit good chain mixing while $\alpha_\eta$ has poor mixing. Poor mixing is indicative of a lack of convergence.}
    \label{fig:14mcmc}
\end{figure}
We have chosen to plot each trace plot separately because the scale of the value ranges for each parameter varies greatly. Overall, there seems to be "good" and "bad" mixing. As we learned from looking at the chain trace plots of the Lotka-Volterra model, we would like to see a dense plot. By eye, we can see some examples of good mixing in the plots for e1, e2, and GI. Plots for $\delta_B$, $\beta_{\eta}$, and $\eta$ show okay mixing. We notice an odd pattern of mixing in the plots for SI, $\mu_r$, $\mu_e$, and $\alpha_{\eta}$ show bad mixing: Their mixing pattern changes after a certain number of samples. We have already taken a burn-in period, but it may be that these final 4 parameters needed more time to converge. We turn to formal techniques of determining convergence to investigate the effects of the bad chain mixing.
\begin{table}[H]
\centering
        \begin{tabular}{c|c c c |c}
            \hline
            \textbf{Parameter} & \textbf{Mean} &  \textbf{Std} & \textbf{ Geweke} &\textbf{Chain Acceptance Rate}\\ 
            \cline{1-5}
            e1 & 9.9199e-05 & 5.6117e-05  &  0.68184 & \multirow{10}{*}{0.43370} \\
            e2 & 9.2374e-05 & 5.9001e-05  & 0.76824\\
            $\delta_B$ & 0.017692 &  0.001341 & 0.98022\\
            SI &  0.6345 & 0.5506  & 0.063996\\
            GI &  30.125 & 6.02  & 0.96526\\
            $\mu_r$ & 0.0013304 & 0.00095325 & 0.028361\\
            $\mu_e$ &  0.0010473 &  0.0010099 & 0.020945\\
            $\alpha_{\eta}$ & 0.04688 &  0.029704 & 0.14961\\
            $\beta_{\eta}$ &  24.723 & 2.0772 & 0.82762\\
            $\eta$ &  0.012852 &  0.0020148 & 0.914
             \\\hline
                          \hline
        \end{tabular}
    \caption{Table listing results of the DRAM chain on the Type 1 Diabetes model for averaged Li data. Parameter means, standard deviations, and convergence diagnostics (Geweke) are calculated. Based on the Geweke values, chain has not converged for all parameters. In fact, parameters SI, $\mu_r$, and $\mu_r$ have significantly low Geweke values.}
    \label{tab:5mcmc} 
\end{table}
Unlike our Lotka-Volterra model, the chain has not converged for all of our parameters. Only 50\% of our parameters have converged and there are some parameters, SI, $\mu_r$, and $\mu_e$ that have a very low Geweke value of $\> 0.1$. 
\par When analyzing the chain acceptance rate of the Lotka-Volterra model, we cited literature that used an acceptance rate of around 25\% to indicate an efficient, convergent, well-performing chain \cite{convergence}. However, other authors argue that for increasingly large and complex systems, this threshold acceptance rate should also increase. In addition, they also point out that in large systems, such as the type 1 diabetes model, it is not feasible to prescribe a universal acceptance rate threshold because the interactions of the model's states and parameters will be specific to that model thereby affecting the overall acceptance rate \cite{converge_threshold}. A more in-depth investigation into the role of chain acceptance rates for large systems will be needed. For now, we are satisfied that the acceptance rate is at least significantly less than 100\%. Given these results good and bad, we are satisfied with the performance of our algorithm. We will discuss more about how we might want to determine good performance in future uses in the Discussion section.
\par Next we visualize the parameter posterior distributions.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/jul10_avg_run1(noIC)_acute_NOD_waveOn_lietal_den.png}
    \caption{DRAM parameter distributions for 14 Type 1 Diabetes parameters for averaged Li data. Some parameters exhibit bimodal distributions. Specifically, $\mu_r$ and $\mu_e$ appear to have bimodal distributions. Recall from \textbf{Table \ref{tab:5mcmc}} that these parameters had very low Geweke values, this indicates that algorithm was not able to determine a global maximum for each parameter as is apparent in their distributions.}
    \label{fig:15mcmc}
\end{figure}
It is not useful for us to try to formally classify these distributions however, we can see some familiar shapes. Parameters $\delta_B$, $\alpha_eta$, and $\beta_{\eta}$ appear log-normal-ish. Others like e1 and e2 appear almost uniform. Lastly, we make note of the parameters whose distributions seem to be bimodal: SI, $\mu_r$, and $\mu_e$ are the most pronounced, but argument could be made for the bimodal pattern in some of the other parameters. The implications of these distributions will be discussed further in the Discussion, but our general thinking is that some parameters may have more than one local maxima and thus more than one optimal range of values (it will likely depend on interactions with other parameters). Altogether, these distributions appear relatively smooth, which unfortunately does not give us any other clues for the lack of convergence that we saw in \textbf{Table \ref{tab:5mcmc}}.
\subsubsection{Working with the distributions}
Now that we have an understanding of the performance of our chain, we can explore the predicted results.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/jul10_avg_run1(withnewTpsan)_acute_NOD_waveOn_lietal_modpred.png}
    \caption{Predicted Glucose model with a 95$\%$ probability range. The averaged acute Li data is plotted over the prediction. While this figure is not particularly informative, we present it for consistency between parameterization of the Lotka-Volterra model (see \textbf{Figures \ref{fig:5mcmc} and \ref{fig:10mcmc}}).}
    \label{fig:16mcmc}
\end{figure}
Just as in the Lotka-Volterra model, in \textbf{Figure \ref{fig:16mcmc}}, we plot the raw data over the predicted model using DRAM parameter means with a 95\% probability range. While at least most of our data points are falling within the 95\% confidence range, from this figure, it appears that our algorithm is not doing a great job of parameterization. Let's look at another model prediction for more information.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/jul9_avg_run1(withnewTpsan)_acute_NOD_waveOn_lietal_meanpred.png}
    \caption{Predicted Glucose model plotted using mean DRAM parameter values. The averaged acute Li data is plotted over the prediction. The prediction appears to capture the original data fairly well. We see the characteristic acute mouse slow steady increase and then spike of glucose indicating diabetes onset.}
    \label{fig:17mcmc}
\end{figure}
In \textbf{Figure \ref{fig:17mcmc}}, we only plot one prediction of the glucose state using the DRAM mean parameter values. From this figure, it seems that our prediction is capturing the original data quite well. We are satisfied with the overall trend of the prediction. (Note: We did not write the code the plots \textbf{Figure \ref{fig:16mcmc}}, so it is difficult for us to tune the plot. The reason that we believe that there are plotting issues in Figure 17 is that when we plot Figure 18, the prediction is actually fairly good. This is something to be investigated in the future.)
\subsection{Parameterizing Mouse 6}
We chose to run the DRAM algorithm on a single mouse because we want to see the results using only raw data. Recall that in the averaged data, we had to make some assumptions about the overall time frame of our data. With mouse 6 data, we can avoid over-generalization and making assumptions. 
\subsubsection{Analyzing the chain}
We begin by looking at the trace plots of the chain for each of the parameters. We performed a burn-in period of 1,000 samples, but we only present the trace plots of the post-burn-in chain.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/jul10_mouse6_run1(noIC)_acute_NOD_waveOn_lietal_traceplot.png}
    \caption{Trace plots of the sampling chain (10,000 samples) for the DRAM MCMC parameterization of the Type 1 Diabetes model on mouse 6 only. Chains for each parameter are plotted separately. We see a mixture of good and poor chain mixing. GI exhibits good mixing while $\mu_r$ and $\mu_e$ exhibit bad mixing. This indicates that chain has not converged for parameters with poor mixing.}
    \label{fig:18mcmc}
\end{figure}
Immediately we see that there is an overall lack of good mixing. Parameter GI seems to be the closest to having good mixing. It is interesting to see now that we can determine some of the parameters that will not have converged. Parameters $\delta_B$, $\beta_{\eta}$, and $\eta$ have pretty dramatic shifts in means during the 100,000 iterations. Recalling the definition of Geweke's diagnostic, these 3 parameters are unlikely to have similar means for the first 10\% and last 50\% of their chain, thus we know that they have not converged. However, these convergences are likely better, in comparison to parameters whose trace plots look like e1, e2, $\mu_r$, $\mu_e$, and $\alpha_{\eta}$. These barely look like classic chain trace plots and their means are almost constantly changing. We turn to formal techniques of determining convergence to investigate the effects of the poor chain mixing.
\begin{table}[H]
\centering
        \begin{tabular}{c|c c c |c}
            \hline
            \textbf{Parameter} & \textbf{Mean} &  \textbf{Std} & \textbf{ Geweke} &\textbf{Chain Acceptance Rate}\\ 
            \cline{1-5}
            e1 & 5.9625e-07 & 4.8352e-07 & 0.023261 & \multirow{10}{*}{0.541} \\
            e2 & 1.0391e-07 &  5.029e-08 & 0.026956\\
            $\delta_B$ & 0.020498 &  0.0057686 & 0.58958\\
            SI &  1.2582   &  0.50705  & 0.027721\\
            GI &  25.949 &  7.0361 & 0.89823\\
            $\mu_r$ & 3.3264e-06 & 2.5351e-06  & 0.063928\\
            $\mu_e$ &  8.8867e-05 & 5.2077e-05 & 0.014021\\
            $\alpha_{\eta}$ & 0.11996 & 0.057717 & 0.029801\\
            $\beta_{\eta}$ &  23.507 & 2.8037  & 0.86778\\
            $\eta$ &  0.015418 &  0.0031396 & 0.81708
             \\\hline
                          \hline
        \end{tabular}
    \caption{Table listing results of the DRAM chain on the Type 1 Diabetes model for mouse 6 only. Parameter means, standard deviations, and convergence diagnostics (Geweke) are calculated. Based on the Geweke values, the chain has not conveged for all parameters. In particular, parameters e1, e2, SI, $\mu_r$, $\mu_e$, and $\alpha_\eta$ have significantly low Geweke values.}
    \label{tab:6mcmc}
\end{table}
Unsurprisingly, we do not have much formal convergence: 60\% of the parameters have a Geweke value of $> 0.1$ and only 3 parameters have truly converged.
\par Again, the chain acceptance rate does not give us much information regarding chain performance but for now, we are satisfied that the acceptance rate is not significantly larger than 50\% and is much less than 100\%. Thus, we believe our chain is giving a satisfactory parameterization. So far, the algorithm has not performed as well on the Mouse 6 data than on the averaged data.
\par Next we visualize the parameter posterior distributions.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/jul10_mouse6_run1(noIC)_acute_NOD_waveOn_lietal_den.png}
    \caption{DRAM parameter distributions for 14 Type 1 Diabetes parameters for mouse 6. For some parameters, like $\mu_e$ and $\alpha_\eta$, the results of \textbf{Table \ref{tab:6mcmc}} are confirmed with bimodal distributions and lack of smoothness. We conclude that for some parameters, the algorithm was unable to determine local mimima.}
    \label{fig:19mcmc}
\end{figure}
Overall these distributions look drastically different than those in \textbf{Figure \ref{fig:15mcmc} }(we will do a more formal comparison of parameter means in a subsequent section). We are most suspicious of the distributions for $\delta_B$, $\mu_e$, and $\beta_{\eta}$. Each of these has a relatively narrow distribution. This is indicative of very few accepted values as they are more concentrated in a narrow range. This tells us that for some parameters, the algorithm is not able to fully explore the parameter space.
\subsubsection{Working with the distributions}
Due to the lack of information that \textbf{Figure \ref{fig:16mcmc}} provided us, we have chosen to omit an analogous figure for this parameterization. We instead turn to a plot of the glucose prediction produced by this run of the algorithm.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/jul10_mouse6_run1(noIC)_acute_NOD_waveOn_lietal_meanpred.png}
    \caption{Predicted Glucose model plotted using mean DRAM parameter values. The Mouse 6 data is plotted over the prediction. Despite poor chain performance for some parameters, the prediction seems to capture the data fairly well.}
    \label{fig:20mcmc}
\end{figure}
From \textbf{Figure \ref{fig:20mcmc}}, it seems that our prediction is capturing the original data quite well. We are satisfied with the overall trend of the prediction. However, we are cautious in trusting the parameter values because of the convergence percentage. Nevertheless, we continue in the next section comparing the overall mean predictions and parameter values.
\subsection{Evaluation}
Our final step in assessing the DRAM algorithm is to evaluate and compare our results from both data sets. We do an evaluation both visually and formally using a mean-squared error score and finally, we compare the actual mean values of the parameters. 
\par Although we only present the full results from 2 different data sets used to parameterize the type 1 diabetes model, we have run the DRAM algorithm on 2 additional individual Mice, 3 and 11 in order to compare the role of the data set. We visually compare the resulting glucose predictions below.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/comp_3_6_11_avg_finalfig.png}
    \caption{Comparing glucose predictions for mouse 3, mouse 6, mouse 11, and averaged acute data. Through the differences in pivot points and slopes of the starting behaviors, we can see that the data the algorithm begins with is important in determining the final model prediction, particularly in determining the diabetes onset time.}
    \label{fig:21mcmc}
\end{figure}
The overall shapes and behaviors are similar between runs. The largest differences are in the starting behavior slopes and diabetes onset times. We attribute most of these differences to the differences in the original data used during the individual parameterizations. For example, mouse 11's data has the earliest onset time and consequently its prediction has the earliest onset time. The same can be said for mouse 3 which has the latest onset time in both the raw data and prediction. This figures tells us that data seems to play a key role in determining the final model predictions and thus the final parameter values. For a more formal comparison, we calculate the root mean squared error for each prediction using its respective raw data.
\begin{table}[H]
\centering
        \begin{tabular}{c | c}
            \cline{1-2}
            \textbf{Data Set}  &\textbf{RMSE}\\
            \hline
            Mouse 3 & 75.2\\
            Mouse 6 & 66.8\\
            Mouse 11 & 66.3\\
            Average & 30.7
             \\\hline
            \hline
        \end{tabular}
    \caption{Comparison of glucose predictions produced by DRAM using original data from mouse 3, 6, 11 and averaged acute data. RMSE was calculated individually. Based on the RMSE scores, the algorithm captures the averaged data best.}
    \label{tab:7mcmc} 
\end{table}
The RMSE scores tell us that the prediction based on averaged data seems to be capturing the original data (average acute) the best. The individual mouse predictions each seem to be performing comparably. Although we seem to have a clear best prediction, it is less clear why the averaged data parameterization produced the best results. Perhaps it is because mouse 3 and 11 do not have as many data points, and there for a less discriminatory likelihood sum of squares function and ultimately a less accurate acceptance criterion.
\par Lastly, we are curious to see how much the final parameter mean values from each run of the algorithm differ. We present the following 3 figures that compare means of mouse 6 and the averaged data parameterization only as these have produced the best results according to \textbf{Figure \ref{fig:21mcmc}} and Table \ref{tab:7mcmc}. Error bars were based on the standard deviations of each parameter mean (these can be found in \textbf{Tables 
\ref{tab:5mcmc}} and \textbf{\ref{tab:6mcmc}}). We have separated the parameter comparisons because of the difference in magnitude as can be observed on the y-axes. Lastly, we note that we choose not to visually compare parameters whose means differed by more more than a magnitude of 10. This is due to 1) difficulty in side-by-side comparison and 2) if parameter values differ by such a great magnitude, it is reasonable to say that they are significantly different without plotting their error bars.
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/mouse6_avg_paramComp1.png}
    \caption{Mean comparison for parameters $\delta_B$, $\alpha_{\eta}$, and $\eta$. Error bars were created using 1 standard deviation in \textbf{Tables \ref{tab:6mcmc} and \ref{tab:5mcmc}}. There does not appear to be a statistical difference between means of these 3 parameters.}
    \label{fig:22mcmc}
\end{figure} 
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/mouse6_avg_paramComp_SIONLY.png}
    \caption{Mean comparison for parameters SI. Error bars were created using 1 standard deviation in \textbf{Tables \ref{tab:6mcmc} and \ref{tab:5mcmc}}. There does not appear to be a statistical difference between the means of SI.}
    \label{fig:23mcmc}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{MCMC_figs/dram_t1d_final/mouse6_avg_paramComp2.png}
    \caption{Mean comparison for parameters GI, $\beta_{\eta}$. Error bars were created using 1 standard deviation in \textbf{Tables \ref{tab:6mcmc} and \ref{tab:5mcmc}}. There does not appear to be a statistical difference between the 2 parameters.}
    \label{fig:24mcmc}
\end{figure}
From these comparisons, we note that 60\% of our parameter means are not significantly different between data sets. This gives us some more insight into the differences between convergent parameters in both runs of the algorithms. For example, the 3 common converged parameters between averaged and mouse 6 predictions are GI, $\beta_{\eta}$, and $\eta$, these parameters seem to be the most similar in value, therefore we can feel relatively confident in their respective mean values. On the other hand, SI is the only parameter that we have compared (\textbf{Figure \ref{fig:23mcmc}}) that did not converge for either run of the algorithm, we are therefore much more suspicious of these values. 
\renewcommand\appendixname{Appendix}
\begin{appendices}
\section{Notes on running DRAM with \texttt{mcmcstat}}
\subsection{Efficiency}  We have been able to run both the Metropolis and DRAM algorithms on our local machines (laptops) However, in general, the DRAM algorithm takes more processing time as it runs through extra steps. In addition, we note that the Lotka-Volterra is very simple, only 2 differential equations, with 4 parameters, however, in models with a greater number of equations and parameters, such as the T1D model, the DRAM process can take upwards of 40 minutes to run on a normal laptop. If you are concerned about computing power, we would recommend running these algorithms on a computer cluster.
\subsection{User options}
The function \texttt{mcmcrun} that implements the DRAM algorithm, allows several options for specifying a prior function. If left unspecified, a uniform prior is assumed, with its bounds located at the upper and lower bounds of the parameter means and standard deviations specified by they user.
\par There also exist several options for specifying estimates for the prior's variance and mean (to be used in the default log-uniform prior). We have not fully explored these, opting instead to write our own prior functions.
\end{appendices}



\section{Things that need to be addressed}
\begin{itemize}
    \item Why Metropolis is a special case of Metropolis Hastings? Why are we choosing this special case?
    \item How does MCMC converge to a posterior distribution.
    \item Why are we looking at both MH and DRAM? Why DRAM even???
    \begin{itemize}
        \item \emph{We use MH because it is the simplest and therefore a good way to get to know MCMC methods}
        \item \emph{We use DRAM because of the ability to search more parameter space and avoid getting stuck in local maxima - I think we can use stuff from when we were comparing a bunch of dif. methods}
    \end{itemize}
    \item Sensitivity matrices (how?)
    \item What covariances mean in context
    \item Smith uses SS, but our writing focuses on explicitly defined prior/likelihood/
    \begin{itemize}
        \item \textit{I think I was able to explain this in the DRAM section?}
    \end{itemize}
    \item Why did we only do DRAM for MCMC? -> based on results of MH v DRAM for Lotka-Volterra, we decide DRAM performs better
    \subsection{Final checks}
    \item insert links to code 
    \item references
    \item making sure when referring to tables, figures, sections etc. all numbers are accurate
    \item Fix all $eta_basal$ to just eta
\end{itemize}



\end{document}