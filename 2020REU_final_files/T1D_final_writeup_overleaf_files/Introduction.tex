\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1.0in]{geometry}
\usepackage{titlesec}
\setcounter{secnumdepth}{4}

\title{Introduction}
\date{June 2020}

\begin{document}

\maketitle
While mathematical and computational approaches have been long-standing within physics, their adoption within other scientific fields is more recent. Over the past 30 years, biology has come to embrace such techniques, especially in the sub-field of modeling. Modeling seeks to simulate, visualize, and analyze emergent properties of a system from simple, initial assumptions\cite{biomodel}. Logically, if one believes a model's assumptions to be correct, its conclusions are also to be accepted \cite{bio_logic}. In biology, models are used to elucidate mechanisms that result in observable biological phenomena. For example, how does a disease spread through a population? With knowledge about the disease, the population, and the mechanics of disease spread, modeling this phenomena can give researchers understanding of an outbreak and insight to inform public health decisions. Models such as this are formulated from both fundamental understandings of the system in question, as well as trends observed in empirical data \cite{biomodel}. 
\par One fundamental type of mathematical model is the dynamical system. Dynamical systems, commonly relying on differential equations, describe time evolution on a state space. They involve state variables, an independent time variable, and parameters. Parameters of a system are often drawn from the system's physical characteristics and take on a single value for the duration of the model. In the disease-spread example, one such parameter might describe the incubation period of the disease being modeled. Another might represent the probability of becoming ill if exposed to a source of infection. These parameters are rarely known with certainty; they are taken from literature or derived statistically from data \cite{biomodel}. Though these methods can result in systems that produce theoretically valid simulations, the value of modeling increases dramatically when data related to the state variables of the system can be incorporated to tune the parameters of the model. This allows a formerly theoretical system to be pushed closer to reality, better reflecting observed phenomena. Again referencing the example above, a reasonable prediction of disease spread can be made simply from biological knowledge about the elements of the system; however, the parameters of the model could be corrected even further using data tracking daily infections. As models are often used as predictive tools or as an \emph{in silico} research method \cite{biomodel}, adherence to reality is vital, making data-based parameter estimation beneficial.
\par Furthermore, data is available at a scale which has never before been seen. This year, there an estimated 59 zetabytes of data will be created. By 2024, this number is expected to grow to 149 zetabytes \cite{data_growth}. In addition to the quantity of data available, accessibility of academic data has grown as common practice has shifted towards data being published alongside journal papers and placed in public repositories or databases. Processing of large data sets has also become more advanced with data science expanding rapidly a field of academic inquiry and industry interest. With such a large quantity of sophisticated data, exciting futures exist in using advanced data science techniques in the parameterization of biological models. 
\par As a result, this paper seeks to act as a tutorial for those interested in the use of these techniques. We explore and compare a selection of three parmeterization techniques, each with its own benefits, use cases, and limitations. The three techniques explored are Markov Chain Monte Carlo (MCMC) methods, Particle Swarm Optimization (PSO), and Kalman Filters, specifically the Unscented Kalman Filter (UKF). While MCMC and PSO are techniques native to pure mathematics, Kalman Filters originate from the field of engineering. Using them in the scenario of parameterization is a new, unique, and exciting application. We additionally present ways in which these techniques can be combined or used in series.
%paragraph introducing MCMC - method, history, use
\par MCMC is a Bayesian technique that simulates the process of sampling values from a $p$-dimensional posterior density function. It has applications ranging from cryptography, to numerical integration, to, of course, parameter fitting. In the context of parameter fitting, this $p$-dimensional PDF would be created by fitting $p$ parameters in the model. From the high dimensional posterior, posterior distributions of the value of each parameter are able to be reconstructed \cite{MCMCintro}. As the name suggests, the process is Markovian; the $p$-dimensional PDF is sampled in an iterative fashion where the sample taken at iteration $t$ relies solely on the value of the sample taken at $t-1$. MCMC consists of a well-established class of algorithms, being developed alongside Monte Carlo Simulation during the 1940s and formalized in 1953 by Metropolis. Motivated by advances in computing power and gaining popularity over the decades, many more advanced algorithms were developed \cite{MCMChistory}. In this paper, we examine the the earliest version of MCMC, the Metropolis algorithm \cite{metropolis1953}, as well as a recently developed, more complex algorithm, Delayed Rejection Adaptive Metropolis (DRAM) \cite{DRAM}.
%paragraph introducing PSO - method, history, use
\par Next, inspired by swarm behavior in birds, Particle Swarm Optimization is a meta-heuristic stochastic approach for both discrete and continuous optimization. A population of simple software agents, known as \emph{particles}, collectively traverses a $p$-dimensional search space where each point in the space represents a solution to the optimization problem. Based on a set of population interaction dynamics, the particles move in consort to find an optimum solution. Developed in 1995 by Kennedy and Eberhart, PSO was first applied as a means to train neural networks \cite{PSOorig}. However, because it acts as a general optimization algorithm, it has become useful for a wide variety of problems, including parameterization. Many variations of classical PSO also exist, altering the way in which particles interact, and thus the way in which the search space is traversed \cite{PSOthesis}. This paper solely examines what is known as \emph{global best} PSO; the original algorithm developed in 1995. 
%paragraph introducing KF - method, history, use
\par Finally, the Kalman Filter is a recursive filtering method, rooted in state space formulation of dynamical systems. \cite{SimonHaykin} This method uses the previous estimate and the observed data to compute the updated estimate for the system. This means that to compute the next estimate, only the previous needs to be stored, which makes this method computationally efficient. Additionally, estimates can be calculated as new data comes in, as opposed to waiting until the entire data set has been gathered. Some common applications of the Kalman Filter include navigation, image processing, and finance. \cite{TamThesis}. However, the Kalman Filter can also be used for parameter estimation, which is what we will be using it for in this paper. 
\par In this paper, we explore the use of these methods by parameterizing two dynamical systems. The first serves as a toy example through which we explain the techniques above, while the second demonstrates their use on a complex model from contemporary research. By taking this two-pronged approach, we aim to provide the reader with a clear, applied understanding of parameterization techniques in a familiar context, as well as a guide to using said techniques in their own research. Our toy system is the well-known simple Lotka-Volterra predator-prey system \cite{Lotka} \cite{Volterra}. The second system examined is a single compartment ODE model for Type 1 Diabetes (T1D) onset in mice. This model was introduced in Shtylla et al. \cite{shtylla2019mathematical} and uses a 12 equation system to model immune cell interactions within the pancreas of a mouse.
\par. Our work takes form as follows: first, we introduce these models in detail, outlining their structure and general dynamics. We concurrently describe the real-world data sets in use for parameterizing each model. After establishing fundamental understandings of the systems and data in question, each parameterization technique: MCMC, PSO, and Kalman Filters, is explained and used to fit each system with optimal parameters. Finally, the results of the techniques are assessed for their quality and compared, before we suggest future steps in this work and opportunities for crossover between the techniques discussed. 
\end{document}

