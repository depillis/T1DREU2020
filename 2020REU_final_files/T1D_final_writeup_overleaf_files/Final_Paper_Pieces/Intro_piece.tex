\section{Introduction} \label{INTRODUCTION} Mathematical and computational approaches have been long-standing within physics, but their adoption within other scientific fields is more recent. Over the past 30 years, biology has come to embrace such techniques, especially in the sub-field of modeling. Modeling seeks to simulate, visualize, and analyze emergent properties of a system from simple, initial assumptions\cite{biomodel}. In biology, models are used to elucidate mechanisms that result in observable biological phenomena. For example, how does a disease spread through a population? With knowledge about the disease, the population, and the mechanics of disease spread, modeling this phenomena can give researchers understanding of an outbreak and insight to inform public health decisions. Models such as this are formulated from both base understandings of the system in question, as well as trends observed in empirical data \cite{biomodel}. 
\par One fundamental type of mathematical model is the dynamical system. Dynamical systems, commonly reliant on differential equations, describe time evolution on a state space. They involve state variables, an independent time variable, and parameters. Parameters of a system are often drawn from the system's physical characteristics and are constant for the duration of the model. In the disease-spread example, one such parameter might describe the incubation period of the disease being modeled. Another might represent the probability of becoming ill if exposed to a source of infection. These parameters are rarely known with certainty; they are taken from literature or derived statistically from data \cite{biomodel}. Though these methods can result in systems that produce theoretically valid simulations, the value of modeling increases dramatically when data related to the state variables of the system can be incorporated to tune the parameters of the model. This allows a formerly theoretical model to be pushed closer to reality, better reflecting observed phenomena. Again referencing the example above, a reasonable prediction of disease spread can be made simply from biological knowledge about the elements of the system; however, the parameters of the model could be corrected even further using data tracking daily infections. As models are often used as predictive tools or as an \emph{in silico} research method \cite{biomodel}, adherence to reality is vital, making data-based parameter estimation beneficial.
\par Furthermore, data is available at a scale which has never before been seen. In addition to the quantity of data available, accessibility of academic data has grown as common practice has shifted towards data being published alongside journal papers and placed in public repositories or databases. Processing of large data sets has also become more advanced with data science expanding rapidly a field of academic inquiry and industry interest. With such a large quantity of data, exciting futures exist in using advanced data science techniques in the parameterization of biological models. 
\par As a result, this paper seeks to act as a tutorial for those interested in the use of these techniques. We explore and compare a selection of three parmeter estimation techniques, each with its own benefits, use cases, and limitations. The three techniques explored are Markov Chain Monte Carlo (MCMC) methods, Particle Swarm Optimization (PSO), and Kalman Filters, specifically the Unscented Kalman Filter (UKF). While MCMC and PSO are techniques native to pure mathematics, Kalman Filters originate from the field of engineering. Using them in the scenario of parameterization is a new, unique, and exciting application. We additionally present ways in which these techniques can be combined in series.
\par MCMC is a Bayesian technique that simulates the process of sampling values from a $p$-dimensional posterior density function. It has applications ranging from cryptography, to numerical integration, to, of course, parameter fitting. In the context of parameter fitting, this $p$-dimensional PDF would be created by fitting $p$ parameters in the model. From the high dimensional posterior, posterior distributions of the value of each parameter are able to be reconstructed \cite{MCMCintro}. As the name suggests, the process is Markovian; the $p$-dimensional PDF is sampled in an iterative fashion where the sample taken at iteration $t$ relies solely on the value of the sample taken at $t-1$. MCMC consists of a well-established class of algorithms, being developed alongside Monte Carlo Simulation during the 1940s and formalized in 1953 by Metropolis \cite{metropolis1953}. Motivated by advances in computing power and gaining popularity over the decades, many more advanced algorithms were developed \cite{MCMChistory}. In this paper, we examine the the earliest version of MCMC, the Metropolis algorithm \cite{metropolis1953}, as well as a recently developed, more complex algorithm, Delayed Rejection Adaptive Metropolis (DRAM) \cite{DRAM1}.
\par Next, inspired by swarm behavior in birds, Particle Swarm Optimization is a stochastic approach for both discrete and continuous optimization. A population of simple software agents, known as \emph{particles}, collectively traverses a $p$-dimensional search space where each point in the space represents a solution to the optimization problem. Based on a set of population interaction dynamics, the particles move in consort to find an optimum solution. Developed in 1995 by Kennedy and Eberhart, PSO was first applied as a means to train neural networks \cite{PSOorig}. However, because it acts as a general optimization algorithm, it has become useful for a wide variety of problems, including parameterization. Many variations of classical PSO also exist, altering the way in which particles interact, and thus the way in which the search space is traversed \cite{PSOthesis}. This paper solely examines what is known as \emph{global best} PSO, the original algorithm developed. 
\par Finally, the Kalman Filter is a recursive filtering method, rooted in state space formulation of dynamical systems \cite{SimonHaykinText}. Developed first by Dr. Rudolf Kalman in 1960 and later improved upon by Dr. Stanley Schmidt, Kalman Filters first found applications in aerospace engineering through projects such as the Apollo Program \cite{NASAPaper}, with current uses in navigation, image processing, and finance \cite{TamThesis}. The recursive algorithm uses the previous estimate and new observed data to compute updated estimates for the system. This means that to compute the next estimate, only the previous needs to be stored, which makes this method computationally efficient \cite{SimonHaykinText}. Additionally, estimates can be calculated as new data comes in, as opposed to waiting until the entire data set has been gathered. While the Kalman Filter was developed for linear systems, recent developments have led to derivativeless filtering methods such as the Unscented Kalman Filter (UKF), which will be explored here \cite{GoveHollingerDual}.
%%% LIT REVIEW %%%
\par In this paper, we tutorial the use of these methods by estimating parameters for two dynamical systems models. The first serves as a case study through which we explain the techniques above, while the second demonstrates their use on a complex model from contemporary research. By taking this two-pronged approach, we aim to provide the reader with a clear, applied understanding of parameterization techniques in a familiar context, as well as a guide to using said techniques in their own research. The model used for this case study is the well-known simple Lotka-Volterra predator-prey model \cite{Lotka} \cite{Volterra}. The second system examined is a single compartment ODE model of Type 1 diabetes (T1D) onset in mice. This model was introduced in Shtylla et al. 2019 \cite{shtylla2019mathematical} and uses a 12 equation system to model immune cell interactions within the pancreas of a mouse.
\par Our work takes form as follows: In Section \ref{PROBLEM_SETUP}, we introduce these models in detail, outlining their structure and general dynamics. We concurrently describe the real-world data sets in use for parameterizing each model. After establishing fundamental understandings of the systems and data in question, each parameterization technique: MCMC, PSO, and Kalman Filters, is explained and demonstrated to fit each system with optimal parameters in Sections \ref{MCMC_SECT}, \ref{PSO_SECT}, and \ref{KF_SECT}, respectively. Note that the parameter estimation techniques are implemented in \textit{MATLAB R2020a v.9.8.0.1359463} \cite{MATLAB:2020b}.  Finally, the results of the techniques are assessed for their quality and compared in Section \ref{RESULTS}, before we draw conclusions in Section \ref{DISCUSSION} and suggest future steps in this work, including opportunities for crossover between the techniques discussed.